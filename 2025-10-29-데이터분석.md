# 📌 1.회귀 알고리즘 - kaggle 자전거 대여 데이터
## 1-1. 회귀 알고리즘 직접구현하기
- y_predict - y → 예측값과 실제값의 차이, 즉 오차(error)
- .mean() → 모든 데이터의 평균 오차
- lr → learning rate (학습률)
- b → bias (편향)
- 만약 예측값이 전체적으로 **실제값보다 크다(양의 오차)**면, (y_predict - y).mean()이 양수 → b에서 그걸 빼니까 bias가 줄어듦 → 예측값 전체가 내려감.
- 반대로 예측값이 **전체적으로 작다(음의 오차)**면, (y_predict - y).mean()이 음수 → b에서 음수를 빼니까 bias가 늘어남 → 예측값 전체가 올라감.
- 즉, b는 전체 그래프를 위아래로 평행이동시키는 역할을 한다.
- 손실함수 전체를 w과 b로 각각 편미분하여 기울기를 구하고 기울기만큼 조정한다.

| 수학식                        | 의미            | 코드                           |
| -------------------------- | ------------- | ---------------------------- |
| ∂L/∂w = mean((ŷ - y) * X) | w에 대한 미분(기울기) | ((y_predict - y) * X).mean() |
| ∂L/∂b = mean(ŷ - y)       | b에 대한 미분(기울기) | (y_predict - y).mean()       |

```py
y_predict = X * w + b

w = np.random.uniform(-1, 1)
b = np.random.uniform(-1, 1)

num_cnt = 100000
lr = 0.0005    # 0.0003

for i in range(num_cnt):
    y_predict = X * w + b

    b = b - lr * (y_predict - y).mean()
    w = w - lr * ((y_predict - y) * X).mean()

    if i % 10000 == 0:
        print(f"반복횟수 : {i}, weight : {w}, bias : {b}")
```

## 1-2. kaggle에서 데이터 받기
- 우선 kaggle에 로그인해서 settings -> api 해서 kaggle.json으로 저장된 파일을 코랩 파일폴더에 업로드한다.
- 해당 케글 competition에 참가 신청을 해야 다운로드 코드가 작동한다.
- 아래코드를 코랩에 입력하면 인증이 되고 데이터를 불러올 수 있다.
- 4번이 해당 데이터를 불러오는 명령어이다.
- 마지막 코드로 인해 압축파일 내부의 데이터를 압축해제할 수 있다.
```py
# kaggle 로부터 직접 데이터 입수하는 방안 :

# 1) API token 발급 및 저장 : kaggle.json
# 2) kaggle 모듈 설치
!pip install kaggle --upgrade

# 3) 준비작업
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# 4) kaggle 파일 온라인을 통해 복사/이동
!kaggle competitions download -c bike-sharing-demand

# zip 파일로부터 데이터 확보 :
!unzip /content/bike-sharing-demand.zip
```

## 1-2. 데이터 selection 및 전처리
- 위에서 받아온 파일을 데이터프레임으로 받아온다.
- 결측치가 존재하지 않고 바꿀 범주형 변수도 날짜정도밖에 없어서 날짜만 따로 처리해주면 된다.
```py
train = pd.read_csv("train.csv")

print(train.shape)
train.head(3)

submission = pd.read_csv("sampleSubmission.csv")

print(submission.shape)
submission.head(1)

train.isnull().sum()
train.describe().T # 기초통계량 확인 -> 전치하면 보기 편함
```
- 날짜 데이터는 아래와 같이 분해하여 컬럼을 만들어둔다.
```py
train["Y"] = pd.to_datetime(train["datetime"]).dt.year
train["M"] = pd.to_datetime(train["datetime"]).dt.month
train["D"] = pd.to_datetime(train["datetime"]).dt.day
train["h"] = pd.to_datetime(train["datetime"]).dt.hour
train["m"] = pd.to_datetime(train["datetime"]).dt.minute
train["s"] = pd.to_datetime(train["datetime"]).dt.second
train["dw"] = pd.to_datetime(train["datetime"]).dt.dayofweek # 0:Mon~6:Sunday

train.head(3)
```

## 1-3. 데이터 분석
- 해당 데이터의 분포를 확인한 결과 skewness > 0이므로 제곱근 변환이나 로그변환을 통해 큰 데이터를 눌러주어야 한다.
- numpy의 log1p함수는 왜도가 큰 데이터를 1+x로 로그변환하여 원래 0인 값도 로그에 넣을 수 있도록 해주면 정규분포와 가까워진 그래프를 확인할 수 있다.
```py
plt.figure(figsize=(10,3))
plt.subplot(1,3,1)
sns.distplot(train["count"]) #skewness > 0
train["count"].skew()
plt.subplot(1,3,2)
sns.distplot(np.log1p(train["count"]))
plt.subplot(1,3,3)
sns.distplot(np.sqrt(train["count"]))
```
- 다른 여러 그래프도 한번 그려본다.
- 온도는 산점도
- 연도별은 boxplot
- 시간은 pointplot으로 시각화한다.
```py
plt.figure(figsize=(10,3))
plt.subplot(1,3,1)
sns.scatterplot(x="temp",y="count",data=train)
plt.subplot(1,3,2)
sns.boxplot(x="Y",y="count",data=train)
plt.subplot(1,3,3)
sns.pointplot(x='h', y="count", data=train)
```
- 아래는 상관계수 행렬형태로 dataprame을 뽑아주는 함수이고 이를 통해 서로의 상관을 분석할 수 있다.
- 이때 수치형 변수만 있어야하므로 datetime은 제거한다.
- 상관계수 행렬은 히트맵으로 보통 시각화한다.
```py
cormatrix = train.drop(columns=["datetime"]).corr()
plt.figure(figsize=(10,10))
sns.heatmap(cormatrix, annot=True, fmt=".2f", linewidths=0.5)
```