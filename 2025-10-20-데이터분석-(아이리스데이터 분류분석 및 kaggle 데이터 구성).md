# 📌 1. t-값의 의미와 구조
## 1-1. t-값의 기본 정의

t-값은 다음과 같이 정의된다:

$$
t = \frac{\hat{\beta}_1 - \beta_{0}}{SE(\hat{\beta}_1)}
$$

- $\hat{\beta}_1$: 현재 표본에서 추정된 회귀계수(기울기)  
- $\beta_{0}$: 귀무가설이 주장하는 계수 값(보통 0)  
- $SE(\hat{\beta}_1)$: 해당 계수의 표준오차(Standard Error) - (표본이 바뀌면서 다르게 계산되는 정도)

즉, **"현재 표본에서 얻은 계수 추정치"가 "귀무가설이 주장하는 값(보통 0)"과 얼마나 떨어져 있는지**를, **"그 계수가 표본마다 흔들릴 수 있는 정도(표준오차)"**로 나눈 비율이다.

---

## 1-2. 현재 추정된 계수란 무엇인가

단순회귀모형을 생각해보자:

$$
y = \beta_0 + \beta_1 x + \varepsilon
$$

데이터를 이용해 회귀분석을 수행하면 $\beta_1$의 추정치 $\hat{\beta}_1$를 얻는다.  
이 값은 **현재 표본 데이터가 말해주는 "최선의 기울기"**이다.

예시:  
- $\hat{\beta}_1 = 2.3$  
→ $x$가 1 증가할 때 $y$가 평균적으로 약 2.3 증가한다는 의미.

---

## 1-3. 데이터가 바뀌면 바뀌는 분산

한 번만 표본을 수집하면 $\hat{\beta}_1$은 하나지만,  
**표본을 여러 번 바꿔서 반복 측정하면 매번 조금씩 다른 $\hat{\beta}_1$이 나온다.**  

이렇게 추정치가 달라지는 정도(흔들림)를 수학적으로 표현한 것이 바로 분산이다:

$$
Var(\hat{\beta}_1) = \frac{\sigma^2}{\sum (x_i - \bar{x})^2}
$$

- $\sigma^2$: 오차항의 분산  
- $\sum (x_i - \bar{x})^2$: $x$ 값들의 퍼짐 정도(분산의 분자 역할)

이 분산의 제곱근이 바로 표준오차다:

$$
SE(\hat{\beta}_1) = \sqrt{\frac{\sigma^2}{\sum (x_i - \bar{x})^2}}
$$

현실에서는 $\sigma^2$를 모르므로 잔차를 이용한 추정치 $s^2$를 사용한다:

$$
SE(\hat{\beta}_1) = \sqrt{\frac{s^2}{\sum (x_i - \bar{x})^2}}
$$

---

## 1-4. t-값이 의미하는 것

이제 검정통계량을 다시 쓰면 다음과 같다:

$$
t = \frac{\hat{\beta}_1 - 0}{SE(\hat{\beta}_1)}
$$

- **분자:** 현재 표본에서 관측된 계수가 0과 얼마나 차이 나는가  
- **분모:** 그 계수가 표본마다 얼마나 흔들릴 수 있는가 (불확실성)

예시:  
- $\hat{\beta}_1 = 2.3$  
- $SE(\hat{\beta}_1) = 0.7$

$$
t = \frac{2.3}{0.7} \approx 3.29
$$

→ 불확실성(0.7)에 비해 추정치(2.3)가 약 3.29배 크다는 뜻이며, 이는 단순한 우연으로 보기 어렵다.

---

## 1-5. 직관적인 이해: 신호 대 노이즈

- 분자: **신호(signal)** – 우리가 발견한 효과의 크기  
- 분모: **노이즈(noise)** – 그 효과가 얼마나 흔들릴 수 있는가

$$
t = \frac{\text{신호}}{\text{노이즈}}
$$

→ 신호가 노이즈보다 충분히 크면(즉, $t$가 크면) “이 효과는 진짜다”라고 판단할 수 있다.

---

## 1-6. 요약

- $t$-값은 "계수의 크기"를 직접 보는 것이 아니라, "계수의 크기 vs 불확실성(SE)"의 비율을 보는 것이다.  
- 이 비율이 크면 → 효과가 우연이 아닐 가능성이 높음 → 귀무가설 기각.  
- 이 비율이 작으면 → 효과가 데이터의 흔들림 속에서 설명 가능 → 귀무가설 채택.

---

# 📌 2. 아이리스 데이터 분석
## 2-1. 아이리스 데이터 전처리
```py
from sklearn.datasets import load_iris
import pandas as pd

iris = load_iris()

# 기존 iris 데이터에 메타데이터처럼 iris["feature_names"]로 특성 이름 리스트를 따로 만들어두었다.
df_iris = pd.DataFrame(iris["data"], columns=iris["feature_names"])
df_iris["label"] = iris["target"]
```

---

## 2-2. 훈련(+검증), 테스트 데이터 분리
- model_selection으로 train데이터와 test 데이터를 선택하여 분리할 수 있다.
- 일단 train, test 둘로 나누면 이는 hold-out 기법이고 일단 이렇게 분리한다.
```py
from sklearn.model_selection import train_test_split # hold out

y = df_iris["label"]
X = df_iris.drop(columns="label") # 대문자 x가 벡터를 의미
print(y.shape, X.shape)

train_x, test_x, train_y, test_y = train_test_split(X,y,train_size = 0.8, random_state=42) # 파레토 확률
print(train_x.shape, test_x.shape,train_y.shape, test_y.shape)
```

---

## 2-3. 일반 의사결정나무 사용
- dt_clf.get_params()를 통해 파라미터를 확인해볼 수 있다.
- 의사결정 나무는 tree 패키지에 있다.
```py
from sklearn.tree import DecisionTreeClassifier

dt_clf = DecisionTreeClassifier(random_state = 42)
dt_clf.fit(train_x, train_y)
```
- 범주형 분류이므로 roc_auc_score로 성능을 테스트한다. test_y, pred_y 순으로 입력한다.
- accuracy_score는 정확도를 평가하는 지표이다.
- 다중분류이기 때문에 predict 대신 predict_proba(확률표)를 사용하여야한다.
- 또한 1대 다 비교를 위해 ovr을 매개변수로 넣는다.
- roc_auc_score와 같은 평가지표는 metrics 패키지에 존재한다. 
```py
from sklearn.metrics import roc_auc_score

pred_y = dt_clf.predict_proba(test_x) # 다중분류이기 때문에 predict 대신 predict_proba를 사용하여야한다.

print(roc_auc_score(test_y, pred_y, multi_class='ovr'))
```

---

## 2-3. 랜덤포레스트 사용
- 데이터를 분할하는 GridSearchCV와 StratifiedKFold는 trian_test_split과 함께 model_selection 패키지에 있다.
- 랜덤 포레스트는 앙상블 기법이므로 ensemble 패키지에 있다.
- n_estimators 즉 트리개수는 100이 기본값이다.
- 너무 많은 초매개변수 후보를 주면 시간이 오래걸리므로 적당히 1~3개만 하면 1분 이내로 정리할 수 있는것 같다.
- 다중 비교일때는 층화추출하여 각 클래스를 골고루 학습할 수 있도록 하는 것이 좋다.
- OVR을 사용하면 일대다로 다중분류문제를 이진분류처럼 다루게 된다.
```py
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, StratifiedKFold # cross validation

rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1) # 병렬로 돌리기 -> 안하니까 grid_search할때 너무 오래걸림

randomforest_param = {
    "n_estimators": [100, 200, 400],         # 트리 개수 -> 100이 기본값
    "max_features": ["sqrt"]            # 특성 샘플링 비율/전략
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # 비율 유지하면서 정렬된 상태가 아닌 섞인 상태에서 샘플링

rf_clf_search = GridSearchCV(
    estimator = rf_clf,
    param_grid = randomforest_param, # 탐색할 파라미터가 많으면 시간이 오래걸림
    cv = cv,
    scoring = "roc_auc_ovr",
    n_jobs=-1
)

rf_clf_search.fit(train_x, train_y) # 그럼에도 hold out 된 테스트 데이터가 필요하다

pred_y = rf_clf_search.predict_proba(test_x) # 다중분류이기 때문에 predict 대신 predict_proba를 사용하여야한다.

print(roc_auc_score(test_y, pred_y, multi_class='ovr'))
print(rf_clf_search.best_params_, rf_clf_search.best_estimator_) # {'max_features': 'sqrt', 'n_estimators': 200} RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)
```

---

# 📌 3. kaggle 데이터 분석 구성
## 3-1. 제공 데이터 구성
- train 파일: x, y 포함한 반면
- test 파일: x 만 준다. y값은 kaggle에서 가지고 있고 이 y값을 예측하는 구성이다.
- submission 파일: 정답만 표기해서 합쳐주는 정답지이다.