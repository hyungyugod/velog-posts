# 📌 1. 계층적 군집 분석(Hierarchical Clustering)에서의 군집 간 거리 정의 방식

## 1-1. 기본 아이디어
- 처음에는 **모든 개체(데이터 점)**을 각각 하나의 군집으로 본다.  
- 가까운 군집끼리 합쳐나가면서 점점 큰 군집을 만든다.  
- 이때 **“군집 간에 얼마나 가까운가?”**를 정의해야 하는데, 바로 그 기준이 **군집 간 거리(distance between clusters)**이다.  

즉, 군집을 합칠 때 어떤 두 군집을 먼저 합칠지 결정하려면 **군집 간 거리를 계산하는 규칙**이 필요하다.

---

## 1-2. 왜 ‘거리 정의 방식’인가?
- 두 개체 간의 거리는 보통 유클리드 거리(Euclidean Distance)로 쉽게 구할 수 있다.  
- 하지만 **군집은 여러 개체가 모인 집합**이므로, **‘군집과 군집 사이의 거리’를 어떻게 정의할지가 문제**다.  

그래서 여러 가지 방법이 생겼다:

### 🔹 단일 연결법 (Single Linkage)
- 두 군집 중 **가장 가까운 두 점**의 거리  
- → 최소 거리 기준  

### 🔹 완전 연결법 (Complete Linkage)
- 두 군집 중 **가장 먼 두 점**의 거리  
- → 최대 거리 기준  

### 🔹 중심 연결법 (Centroid / Average Linkage)
- 두 군집의 **중심점(평균 좌표) 간 거리** 또는 평균 거리  
- → 평균 거리 기준  

### 🔹 와드 연결법 (Ward’s Method)
- 두 군집을 합쳤을 때 **군집 내부 분산 증가량**을 최소화하는 쌍을 선택  
- → 분산 최소화 기준  

---

## 1-3. 정리
- 이 네 가지 방식은 모두 **“군집과 군집 간의 거리를 어떻게 정의할 것인가”**를 규정한다.  
- 즉, 단일·완전·중심·와드 연결법은 군집 합병 과정에서 사용할 **거리 측정 규칙**이다.

# 📌 2. 분산분석, 회귀식에서 설명력 검정

| 항목 | 풀 텀 (Full Term) | 제곱합 (SS, Sum of Squares) | 자유도 (df, Degree of Freedom) | 평균제곱 (MS, Mean Square) | 의미 |
|------|------------------|----------------------------|-------------------------------|----------------------------|------|
| 총변동 | Total | \(SST = \sum (Y_i - \bar{Y})^2\) | \(df_T = n - 1\) | \(MST = \dfrac{SST}{df_T}\) | 전체 데이터 변동 |
| 회귀변동 | Regression | \(SSR = \sum (\hat{Y}_i - \bar{Y})^2\) | \(df_R = p\) (설명변수 개수) | \(MSR = \dfrac{SSR}{df_R}\) | 회귀모형이 설명하는 변동 |
| 오차변동 | Error (Residual) | \(SSE = \sum (Y_i - \hat{Y}_i)^2\) | \(df_E = n - p - 1\) (절편 포함 시) | \(MSE = \dfrac{SSE}{df_E}\) | 모형이 설명하지 못한 변동 (잔차) |

---

## F-검정 공식
\[
F = \frac{MSR}{MSE}
\]

# 📌 3. 선형회귀의 주요 가정과 확인 시점

| 가정 | 의미 | 확인 방법 | 확인 시점 |
|------|------|-----------|-----------|
| 선형성 (Linearity) | 독립변수와 종속변수의 관계가 선형적이어야 함 | 산점도, 잔차 vs 적합값 그래프 | **모형 전/후 모두** (탐색적 분석 + 잔차 진단) |
| 독립성 (Independence) | 잔차들이 서로 독립이어야 함 (자기상관 없음) | Durbin–Watson 검정, 시계열 플롯 | **모형 적합 후** |
| 등분산성 (Homoscedasticity) | 잔차 분산이 일정해야 함 (x 값이 커져도 잔차 분포 일정) | 잔차 vs 적합값 그래프, Breusch–Pagan 검정 | **모형 적합 후** |
| 정규성 (Normality of Residuals) | 잔차가 정규분포를 따라야 t/F 검정, 신뢰구간 해석 가능 | Q–Q plot, 히스토그램, Shapiro–Wilk 검정 | **모형 적합 후** |

---

## 정리
1. **모형 세우기 전**: 산점도, 탐색적 분석으로 선형성 가정이 대략 맞는지 본다.  
2. **모형 적합 후**: 잔차를 통해 독립성, 등분산성, 정규성을 진단한다.  
3. **정규성은 데이터(Y) 자체가 아니라 잔차**에 대해 확인한다.

# 📌 4. 엘라스틱넷

## 라쏘 vs 릿지 vs 엘라스틱 넷 (변수 개수가 많고, 상관성이 높은 경우)

| 방법 | 계수 추정 경향 | 변수 선택 여부 | 상관된 변수 처리 방식 | 특징 |
|------|----------------|----------------|----------------------|------|
| **릿지 (Ridge)** | 모든 계수를 조금씩 줄임 | ❌ (계수를 0으로 만들지 않음) | 상관된 변수들의 계수를 모두 줄여서 같이 유지 | 다중공선성 완화, 안정적인 추정 |
| **라쏘 (Lasso)** | 일부 계수를 아예 0으로 만듦 | ✅ (변수 선택 효과) | 상관된 변수 중 하나만 남기고 나머지는 0으로 제거 | 변수 선택 가능, 해석 쉬움 |
| **엘라스틱 넷 (Elastic Net)** | 릿지+라쏘 혼합 (비율 조절) | ✅ (변수 선택 효과 유지) | 상관된 변수들을 그룹으로 묶어 적절히 선택 | 변수 선택 + 다중공선성 완화 동시 달성 |
