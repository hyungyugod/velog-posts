# 📌 1. 8회 기출
## 1-1. 1유형
- 해당 기출에서 얻어갈 것은 nlargest 함수이다. 
- n과 특정 칼럼을 적으면 정렬하지 않아도 n개만 골라 정렬되어 가장 큰 순으로 n개를 제공한다.
```py
a = df.nlargest(2, '관광객비율')['사업'].iloc[1]
b = df.nlargest(2, '관광')['공무'].iloc[1]
```
- 스케일링을 for문으로 돌려서 해결했는데 코딩 수가 이게 더 짧은 거 같다.
```py
from sklearn.preprocessing import MinMaxScaler

cols = ['co', 'nmhc']

for col in cols:
  ms = MinMaxScaler()
  df[col] = ms.fit_transform(df[[col]])

co_std = df['co'].std()
nmhc_std = df['nmhc'].std()

print(round(co_std - nmhc_std, 3)) # -0.017
```

## 1-2. 2유형
- train.describe(include='O')를 해봐야 삭제할 설계변수를 골라낼 수 있다.
- 이를 통해 초반 설계변수를 삭제하고 시작하는것에 유의하자
```py
# 설계변수 삭제
# print(train.shape, test.shape)
train = train.drop('customerID', axis=1)
test = test.drop('customerID', axis=1)
# print(train.shape, test.shape)

# 타겟 데이터 분리 및 인코딩
target = train.pop('TotalCharges')
obj_cols = train.select_dtypes('object').columns

# for col in obj_cols:
#   if len(set(train[col])) < len(set(test[col])):
#     print(col)

# oh
# train = pd.get_dummies(columns=obj_cols, data=train)
# test = pd.get_dummies(columns=obj_cols, data=test)

# le
from sklearn.preprocessing import LabelEncoder

for col in obj_cols:
  le = LabelEncoder()
  train[col] = le.fit_transform(train[col])
  test[col] = le.transform(test[col])

# 검증데이터 분리
from sklearn.model_selection import train_test_split
x_tr, x_val, y_tr, y_val = train_test_split(train, target, test_size=0.2, random_state=42)
# print(x_tr.shape, x_val.shape, y_tr.shape, y_val.shape)

# 모델 적합 및 평가
from lightgbm import LGBMRegressor
model = LGBMRegressor(verbose=-1, random_state=42, max_depth=3, n_estimators=100, learning_rate=0.1)

# from sklearn.ensemble import RandomForestRegressor
# model = RandomForestRegressor(random_state=42, max_depth=3, n_estimators=100)

model.fit(x_tr, y_tr)
pred1 = model.predict(x_val)

from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(y_val, pred1))

# oh lgbm max_depth=3, n_estimators=100, learning_rate=0.1 863.1815315929767

# 최종 예측 및 제출
pred = model.predict(test)
submit = pd.DataFrame({
    'pred':pred
})
submit.to_csv('result.csv', index=False)
print(pd.read_csv('result.csv'))
```

## 1-3. 3유형
- 계수 유희확률에 대해 계산해야할때 상수항도 포함되어있는 것을 조심해야한다.
- model.pvalues, model.params는 series라 []을 통해 특정 행들에 접근할 수 있다. 슬라이싱도 가능하다. 
- model.params['Brain']이면 인덱스가 Brain인게 출력되는 것이다.
- sum(model.pvalues[1:] > 0.05) 이렇게해야 상수항을 빼고 독립변수의 개수를 구할 수 있다.
```py
# 1) 로지스틱 회귀분석을 위한 포뮬라 생성
formula = "Churn ~ AccountWeeks + ContractRenewal + DataPlan + DataUsage + CustServCalls + DayMins + DayCalls + MonthlyCharge + OverageFee + RoamMins"


# 2) 로지스틱 회귀 모델 생성 및 학습
from statsmodels.formula.api import logit
model = logit(formula, data=df).fit()

# 3) 유의하지 않은 독립변수의 개수 구하기
print(model.summary())
sum(model.pvalues[1:] > 0.05)
```
- DataUsage’ 변수가 5만큼 증가할 때 오즈비(Odds Ratio)를 구하시오.
- 식을 생각해보면 먼저 계수에 5배를 하고 exp하는게 맞다.
```py
# 1) 변수의 회귀계수 추출
import numpy as np
coef = model.params['DataUsage']

# 2) 오즈비 계산
round(np.exp(coef * 5),3)
```
- 예측값을 꺼낼때 결과가 series이므로 값이 하나여도 [0]으로 꺼내주는게 깔끔하다.
```py
# 1) 새로운 데이터 생성
new_data = pd.DataFrame({'Brain':[90], 'Height':[70], 'Weight':[150]})

# 2) PIQ 예측
pred = model.predict(new_data)
print(pred)
print(round(pred[0]))
```

# 📌 2. 분산분석 연습문제 
## 1-1. 일원분산분석
- shapiro검정에서는 숫자들이 있는 열벡터 하나만 넣어야한다.
- 그리고 dir을 사용할때 해당 위치까지 불러놓고 사용해야한다.
```py
import statsmodels.api
dir(statsmodels.api)
```
- anova_lm 불렀을때 from statsmodels.stats.anova import anova_lm 이렇게 statsmodels.stats 아래에 anova가 있음을 잘 이해야한다.

| 분석/검정                     | 검정(BT, ANOVA), 통계량, 여러 검정 패키지      |
| ------------------------- | ---------------------------------- |
| `statsmodels.formula.api` | ols, glm 등 수식 기반 모델 빌터             |
| `statsmodels.api`         | 모델 인터페이스(예: sm.OLS), 데이터 구조        |
| `statsmodels.stats`       | t-test, chi², ANOVA, 정규성검정 등 검정 도구 |

- 또 report = anova_lm(model)에서 report의 결과는 아래와 같이 해석한다.

| 구분           | df         | sum_sq                    | mean_sq                     | F                  | PR(>F)            |
| ------------ | ---------- | ------------------------- | --------------------------- | ------------------ | ----------------- |
| **groups**   | 집단 수 − 1   | **모형(집단)으로 설명되는 제곱합 SSR** | **SSR/df → 집단 간 평균제곱(MST)** | **모형효과 / 오차효과 비율** | **F검정의 유의확률(p값)** |
| **Residual** | 전체자료 − 집단수 | **오차 제곱합 SSE**            | **SSE/df → 잔차 평균제곱(MSE)**   | 계산대상 X             | 계산대상 X            |

```py
# 정규성 검정 -> 전부 정규분포를 따름
conda = df['groups'] == 'group_A'
condb = df['groups'] == 'group_B'
condc = df['groups'] == 'group_C'
condd = df['groups'] == 'group_D'

box = [conda, condb, condc, condd]

from scipy import stats
for c in box:
  st, pv = stats.shapiro(df[c]['scores'])
  if pv < 0.05:
    print(c)
  print(pv)

# 0.9051800443853569
# 0.6678172590861611
# 0.44732595113862045
# 0.25824165549017347

# 등분산검정 -> 등분산
st, pv = stats.levene(df[conda]['scores'], df[condb]['scores'], df[condc]['scores'], df[condd]['scores'])
print(pv)
# 0.17270284963232108


from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

formula = 'scores ~ groups'
model = ols(formula, data=df).fit()
report = anova_lm(model)
print(report)

# 잔차자유도 Residual df -> 36.0
# 성적의 제곱합을 구하시오. groups sum_sq -> 411.8
# 성적의 평균 제곱을 구하시오. groups -> mean_sq 137.266667
# F-통계량의 값을 구하시오. groups F 34.174274
# 성적에 대한 p-value를 구하시오. PR(>F) 0.0000000001

print('{:.10f}'.format(1.240642e-10))
```

## 1-2. 이원 분산분석
- 아노바 테이블에서 각 요인별로 집단 간 차이에 어떤 영향을 주는지 검정통계량과 pvalue를 구할 수 있다.
- C를 붙이는 것은 왠만하면 처리해주는게 좋은 거 같긴하다.
- 이 문제에서 안붙이고 했는데 붙이고 했을때와 답이 달랐다.

| 상황                      | 이유                                |
| ----------------------- | --------------------------------- |
| 숫자로 코딩된 범주 (0/1/2)      | 자동 처리하면 숫자로 해석됨 → 회귀계수가 왜곡됨       |
| interaction(교호작용) 포함할 때 | `C(A)*C(B)` 와 `A*B` 결과는 다를 수 있음   |
| ANOVA · 이원분산 · 실험설계     | 수준(Level) 개수가 많을 때 자동 인식 실패 사례 있음 |
| 로지스틱·GLM 등 복합 모델        | 모델 종류에 따라 처리 방식이 다를 수 있음          |


```py
import pandas as pd
df = pd.read_csv("https://raw.githubusercontent.com/lovedlim/inf/refs/heads/main/p3/tomato2.csv")

from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

model = ols('수확량 ~ C(비료유형) * C(물주기)', data=df).fit()
report = anova_lm(model)
print(report)

# 비료 유형에 따른 토마토의 수확량 평균에 차이가 있는가를 검정하기 위한 검정 통계량을 구하시오. 위의 통계량에 대한 p-value를 구하시오.
# 3.264652  0.052143

# 위의 검정 결과를 유의 수준 0.05하에서 귀무가설을 기준으로 (채택/기각)중 선택하여 입력하시오.
# 귀무가설 채택


# 물 주기에 따른 토마토의 수확량 평균에 차이가 있는가를 검정하기 위한 검정 통계량을 구하시오. 위의 통계량에 대한 p-value를 구하시오.
# 8.571622  0.006459


# 위의 검정 결과를 유의 수준 0.05하에서 귀무가설을 기준으로 (채택/기각)중 선택하여 입력하시오.
# 귀무가설 기각


# 비료 유형과 물 주기 간의 상호작용은 토마토 수확량에 영향이 있는지 검정하기 위한 검정 통계량을 구하시오.
# 위의 통계량에 대한 p-value를 구하시오.
# 1.301171  0.287135

# 위의 검정 결과를 유의 수준 0.05하에서 귀무가설을 기준으로 (채택/기각)중 선택하여 입력하시오.
# 귀무가설 채택
```



# 📌 3. OLS와 ANOVA(`anova_lm`)의 관계

## 3-1. 회귀모형의 분산 분해

SST = SSR + SSE

## 3-2. ANOVA의 F 통계량

MSR = SSR/df_reg  
MSE = SSE/df_resid  
F = MSR/MSE

## 3-3. `anova_lm(model)`이 하는 일

- OLS 결과값 기반으로 SST, SSR, SSE 계산
- F통계량 및 p-value 계산