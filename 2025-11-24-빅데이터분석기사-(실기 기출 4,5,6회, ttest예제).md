# 📌 1. 4회 기출
## 1-1. 1유형
- 판다스에서는 cond1 = 0.4 < x < 0.5 이런식으로 할 수 없다.
- 무조건 &를 활용해 두 조건을 연결해야한다.
- (loves반응+wows반응)/(reactions반응) 비율이 0.4보다 크고 0.5보다 작으면서, type 컬럼이 'video'인 데이터의 갯수
```py
x = (df['loves'] + df['loves']) / df['reactions']

cond1 = (0.4 < x) &  (x < 0.5)
cond2 = df['type'] == 'video'

print(len(df[cond1 & cond2])) # 141
```
- df['date_added'].str.split() 여기까지하면 각 셀이 split된 dataframe이라 여기서 또 특정번째 칼럼만 선택하려면 그냥 [2] 이러는게 아니라 .str[2]으로 정확히 선택해 주어야 한다. 전자는 dataframe의 3번째 행이 출력된다.
```py
cond1 = df['country'] == 'United Kingdom'

x1 = df['date_added'].str.split().str[0] == 'January'
x2 = df['date_added'].str.split().str[2] == '2018'

cond2 = x1 & x2

print(len(df[cond1 & cond2])) # 6
```
- 근데 이를 datetime으로도 가능하다.
- September 25, 2021 형식이어도 to_datetime을 걸면 날짜형으로 알잘딱으로 변형된다. 날짜는 우선 to_datetime을 시도해보고 안되면 위와같은 방법을 사용해도 될 것 같다.
- 아래서 중요한 것은 datetime을 비교할때는 숫자와 비교해야한다.
```py
cond1 = df['country'] == "United Kingdom"

df['date_added'] = pd.to_datetime(df['date_added'])
df['year'] = df['date_added'].dt.year
df['month'] = df['date_added'].dt.month


cond2 = df['year'] == 2018
cond3 = df['month'] == 1

print(len(df[cond1 & cond2 & cond3]))
```
- 또 다른 방법은 datetime 데이터 타입의 between 메서드를 사용하는 것인데 이를 사용해서 특정 날짜구간의 값인지 아닌지를 판단하는 bool series를 반환받을 수 있다.
- 이때 주의할 점은 위처럼 년, 월 따로따로가 아니라 -로 이어진 형태일 때는 문자열로 비교해야한다.
```py
cond1 = df['country'] == "United Kingdom"
df['date_added'] = pd.to_datetime(df['date_added'])
cond2 = df['date_added'].between('2018-1-1', '2018-1-31')
print(len(df[cond1 & cond2]))
```
- 아래처럼 contains를 이용하는 방법도 있다.
```py
str1 = "2018"
str2 = "January"
cond2 = df['date_added'].str.contains(str1)
cond3 = df['date_added'].str.contains(str2)
```
- 만약 띄어쓰기나 소문자 대문자가 나라이름에 섞여있다면 일괄적으로 처리한 후 진행하는 것도 좋다.
```py
# 띄어쓰기 제거
df['country'] = df['country'].str.replace(' ','')

# 소문자로 변경
df['country'] = df['country'].str.lower()
df['country']
```

## 1-2. 2유형
- f1_score average 매개변수를 macro로 해야하는 경우 -> help(f1_score)로 매개변수 설정값들 확인할 수 있다.
- F1이 높다는 건 precision도 좋고 recall도 좋다는 뜻이다.
- 우선 인코딩 결정 (일반적으로 labelencoding이 트리모델에서는 잘먹음) -> 모델 결정 -> 하이퍼 결정 -> 이후 인코딩 한번만 더 바꿔보기
```py
# 분류분석 - f1 macro
# 결측치 x, 이상치, 인코딩
obj_cols = train.select_dtypes(include='object').columns

# for col in obj_cols:
#   if set(train[col]) != set(test[col]):
#     print(col, "x") -> 겹치는 값 없음

# oh
# train = pd.get_dummies(columns=obj_cols, data=train)
# test = pd.get_dummies(columns=obj_cols, data=test)

# lb
from sklearn.preprocessing import LabelEncoder

for col in obj_cols:
  le = LabelEncoder()
  train[col] = le.fit_transform(train[col])
  test[col] = le.transform(test[col])

# 검증 데이터 분리
from sklearn.model_selection import train_test_split
x_tr, x_val, y_tr, y_val = train_test_split(train.drop('Segmentation', axis=1), train['Segmentation'], test_size=0.2, random_state=42)
# print(x_tr.shape, x_val.shape, y_tr.shape, y_val.shape)

# 모델 학습 및 평가
#lightgbm
from lightgbm import LGBMClassifier
model = LGBMClassifier(verbose=-1, random_state=42, max_depth=3, n_estimators=200, learning_rate=0.1)

#rf
# from sklearn.ensemble import RandomForestClassifier
# model = RandomForestClassifier(random_state=42, max_depth=3, n_estimators=100)

model.fit(x_tr, y_tr)
pred1 = model.predict(x_val)

from sklearn.metrics import f1_score
print(f1_score(y_val, pred1, average='macro')) 

# lightgbm lb max_depth=3, n_estimators=100, learning_rate=0.1 0.5242271782480223

# 평가 및 제출
pred = model.predict(test)
submit = pd.DataFrame({
    'ID':test['ID'],
    'pred':pred
})

submit.to_csv('submit.csv', index=False)

print(pd.read_csv('submit.csv'))
```

# 📌 2. 5회 기출
## 2-1. 1유형
- 깔끔하게 칼럼 개수를 필요한 것만 추리면 괜찮을지 모르지만 칼럼이 많을 경우면 뒤에서부터 iloc를 세는 것이 편리하다.
- 그리고 칼럼이 많을 때는 pd.set_option('display.max_columns', None)을 적극 활용하자
```py
pd.set_option('display.max_columns', None)

# your code
df['순전입학생'] = df['전입학생수(계)'] - df['전출학생수(계)']
cols = ['학교명', '순전입학생', '전체학생수(계)']
answer = df[cols].sort_values('순전입학생', ascending=False).iloc[0,2]
print(int(answer)) # 230
```

## 2-2. 2유형
- train에는 없는데 test에는 있는 코드 잡아내기 -> 이게 없으면 그냥 분리해서 인코딩 진행해도 무방함
```py
for col in obj_cols:
  if len(set(train[col])) < len(set(test[col])):
    print(col,'x')
```
- 전체코드는 아래와 같다.
```py
obj_cols = train.select_dtypes(include='object').columns

# for col in obj_cols:
#   if len(set(train[col])) < len(set(test[col])):
#     print(col,'x')

# oh
train = pd.get_dummies(columns=obj_cols, data=train)
test = pd.get_dummies(columns=obj_cols, data=test)

# le
# from sklearn.preprocessing import LabelEncoder

# for col in obj_cols:
#   le = LabelEncoder()
#   train[col] = le.fit_transform(train[col])
#   test[col] = le.transform(test[col])

# 검증데이터 분리
from sklearn.model_selection import train_test_split
x_tr, x_val, y_tr, y_val = train_test_split(train.drop('price',axis=1), train['price'], test_size=0.2, random_state=42)
# print(x_tr.shape, x_val.shape, y_tr.shape, y_val.shape)

# 모델 적합 및 평가
from lightgbm import LGBMRegressor
model = LGBMRegressor(verbose=-1, random_state=42, max_depth=5, n_estimators=500, learning_rate=0.05)

# from sklearn.ensemble import RandomForestRegressor
# model = RandomForestRegressor(random_state=42, max_depth=3, n_estimators=100)


model.fit(x_tr, y_tr)
pred1 = model.predict(x_val)
from sklearn.metrics import root_mean_squared_error
print(root_mean_squared_error(y_val, pred1))

# oh max_depth=5, n_estimators=500, learning_rate=0.05 1280.2620352845165
  

# 예측 및 제출
pred = model.predict(test)
submit = pd.DataFrame({
    'pred':pred
})

submit.to_csv('result.csv', index=False)

print(pd.read_csv('result.csv'))

```

# 📌 3. 6회 기출 
## 3-1. 1유형
- 여러 날짜컬럼을 동시에 datetime으로 바꾸는 것은 apply함수를 사용해 pd.to_datetime을 전체 열에 적용시키면 된다.
- datetime의 차이는 timedelta데이터 타입이 되는데 이를 분 단위로 바꾸려면 dt.total_seconds()를 이용할 수밖에 없다.
- 전체를 초로 나눈뒤에 이를 60으로 나눠서 분단위 시간으로 변경한다.
```py
cols = ['출동시간', '도착시간']
df[cols] = df[cols].apply(pd.to_datetime)
df['이동시간'] =  df['도착시간'] - df['출동시간']

df1 = df.groupby('소방서')['이동시간'].mean().reset_index()
df1['이동시간'] = df1['이동시간'].dt.total_seconds() / 60
df1['이동시간'].sort_values(ascending=False).apply(round) # 81
```
- 아니면 마지막줄만 이렇게 변경해도된다.
- 최대값을 찾아주는 함수가 있는데 굳이 돌아갈 필요가 없다.
```py
int(df1['이동시간'].max()) # 81
```
- 선택한 열들만 합치는 방법은 df.iloc[:, 2:].sum(axis=1) 이렇게 열방향으로 합쳐도 된다.
- df['전체/교사'].idxmax()는 가장 큰 값을 가지는 행의 인덱스를 반환해준다.
```py
# 1. 전체 학생수
df['전체'] = df.iloc[:, 2:].sum(axis=1)
df.head(2)

# 2. 교사 한 명당 맡은 학생 수 (전체/교사)
df['전체/교사'] = df['전체']/df['교사수']
df.head(2)

df['전체/교사'].idxmax()
print(int(df.loc[7, '교사수']))

# 정렬해서 찾는 방법
df.sort_values('전체/교사', ascending=False)
```
- df.groupby('y')['m'].mean().idxmax() 에서 reset_index를 안하면 바로 월평균이 제일 높은 연도를 찾을 수 있다. -> 연도가 인덱스기때문
- 연도의 월평균이면 연도에서 1달당 얼마나 범죄가 발생했는지 구하는 것이므로 sum을 한 후 12로 나누어서 계산한다.
- datetime을 포멧팅할땐 format 매개변수의 인자로 현재 테이블의 표기를 표현해주면 된다.
```py
df['날짜'] = pd.to_datetime(df['날짜'], format='%Y년 %m월')
df['y'] = df['날짜'].dt.year

df['총범죄'] = df.iloc[:,1:7].sum(axis=1)

df = df[['y', '총범죄']]
df = df.groupby(['y'])['총범죄'].sum()/12
print(round(df.max()))
```

## 3-2. 2유형
- 다중분류에서 결과를 칼럼형태로 제공되도록 하게 되어있더라도 그냥 하던대로 하면 상관없다.
- KeyError: 'Heat_Load' 이렇게 문자칼럼 비교할때 처음에 나오면 target일 확률이 크니 target을 분리하고 가보자
- 진전이 없다가도 learning_rate를 확 낮추고 다시 estimator를 올리면 값이 확 커질 때가 있다.
```py
# 인코딩
target = train.pop('Heat_Load')
obj_cols = train.select_dtypes('object').columns

# for col in obj_cols:
#   if len(set(train[col])) < len(set(test[col])): 
#     print(col,'x')

# oh 
train = pd.get_dummies(columns=obj_cols, data=train)
test = pd.get_dummies(columns=obj_cols, data=test)

# le
# from sklearn.preprocessing import LabelEncoder

# for col in obj_cols:
#   le = LabelEncoder()
#   train[col] = le.fit_transform(train[col])
#   test[col] = le.transform(test[col])

# 검증 데이터 분리
from sklearn.model_selection import train_test_split
x_tr, x_val, y_tr, y_val = train_test_split(train, target, test_size=0.2, random_state=42)

# 모델 적합 및 평가
from lightgbm import LGBMClassifier
model = LGBMClassifier(verbose=-1, random_state=42, max_depth=5, n_estimators=300, learning_rate=0.02)

# from sklearn.ensemble import RandomForestClassifier
# model = RandomForestClassifier(random_state=42, max_depth=3, n_estimators=100)

model.fit(x_tr, y_tr)
pred1 = model.predict(x_val)

from sklearn.metrics import f1_score
print(f1_score(y_val, pred1, average='macro'))

# oh max_depth=5, n_estimators=300, learning_rate=0.02 0.0.0.9421933621933622

# 예측 및 제출
pred = model.predict(test)
submit = pd.DataFrame({
    'pred':pred
})

submit.to_csv('result.csv',index=False)

print(pd.read_csv('result.csv'))
```
- 크로스 밸리데이션 수행이 어떻게 되는지는 일단 알아만 두자 후순위가될 것 같다.
```py
# 크로스 밸리데이션 수행(5-fold)
from sklearn.model_selection import cross_val_score
result = cross_val_score(rf, train, target, cv=5, scoring='f1_macro')
```

## 3-3. 3유형 (적합도 검정)
- Q1. 항암약 위약을 투여 받은 환자의 부작용은 감기약 위약을 투여 받은 환자의 부작용 분포와 차이가 있는가? (적합도 검정)
```py
# 항암약 부작용
import pandas as pd
df = pd.DataFrame({ "항암약":[4,4,3,4,1,4,1,4,1,4,4,2,1,4,2,3,2,4,4,4] })
# 1: '아픔', 2: '조금 아픔', 3: '속쓰림', 4: '무증상'

# 감기약 부작용
# 1. 아픔: 10%
# 2. 조금 아픔 5%
# 3. 속 쓰림 15%
# 4. 무증상: 70%
```
- 1-1. 항암약을 투여 받은 환자 중 '무증상'의 비율을 0과 1사이로 구하시오.
- 각 범주의 비율을 보려면 normalize=True를 주면 된다.
```py
df.value_counts(normalize=True) # 0.55
```
- reset_index는 함수이므로 reset_index() 이렇게 사용해야한다. 이는 데이터 프레임을 반환한다.
- sort_index()는 index 기준으로 정렬한다.
- 카이제곱 검정의 chisqure는 1차원 배열을 값으로 넣어야 한다.
- 1차원 배열로 만드는 법은 가장 간단한게 인덱스 제외 1차원 데이터프레임에서 to_list()함수를 사용하면 바로 파이썬 리스트로 변환된다. 이를 사용한다.
- 리스트 * 숫자는 벡터연산이 아니라 반복이다.
- chisquare는 관찰값, 기대값 순으로 받으며 결과가 튜플이므로 분배해서 할당받을 수 있다.
- st가 검정 통계량, pv가 pvalue이다.
- 리스트는 전체표본수 * 확률값으로 기대도수를 구한다.
```py
from scipy import stats
l = len(df)
ob = df.value_counts().sort_index().to_list()
ex = [0.1*l, 0.05*l, 0.15*l, 0.7*l]
st, pv = stats.chisquare(ob, ex)
print(st, pv)
```

## 3-4. 3유형 (다중 선형회귀)
- model에서 summary는 모델의 기능 즉 함수이다.
- 공식은 문자열로 적어서 머신에 넣어주면 되고 fit()으로 학습하는 것을 잊으면 안된다.
- 이중 두 변수를 고정하고 한변수의 p-value만 구하라고 하면 이는 다중회귀에서의 부분회귀를 묻는 질문이고 summary 안에서 wind의 p-value 를 보면 그게 바로 “다른 변수들을 고정하고 난 후 wind의 고유한 효과"(고유한 흔들림)를 평가한 값이다.
```py
from statsmodels.formula.api import ols
formula = 'temperature~solar + wind + o3'
model = ols(formula, data=df).fit()
print(model.summary()) 
```
- solar:100, wind:5, o3:30일 때 예측값과 그에 대한 95% 신뢰구간을 구하시오.
- 이 문제는 적합된 model 즉 식을 이용하여 새로운 데이터를 계산하고 특정 유의수준에 맞게 범위까지 제공하라는 뜻이다. 이는 dataframe으로 예측값을 만들어서 대입하고 get_prediction으로 결과를 받은뒤 summary_frame으로 alpha값을 주고 결과를 확인하면 된다.
```py
data = pd.DataFrame({
    'solar':[100],
    'wind':[5],
    'o3':[30]
})

result = model.get_prediction(data)
print(result.summary_frame(alpha=0.5))
```

# 📌 4. 단일표본, 독립표본, 대응표본 검정 연습문제
## 4-1. 단일표본 검정
- 커피 제조회사에서는 새로 출시한 커피의 카페인 함량이 평균 95mg 미만이라고 주장하였다. 그 주장이 사실인가를 알아보기 위하여..
- {:.10f} 구조 -> { [필드명] : [형식 옵션] }
- : 콜론은 형식 옵션(format specifier) 시작을 알린다
- 점 + 숫자 = 소수점 이하 자리수 -> .10 → 소수점 아래 10자리
- f는 **fixed-point notation (고정 소수점 표현)**을 의미
- 지수 표기 e → 1.234e-05
- 고정 소수점 f → 0.00001234
- '{:.10f}'.format(pv) 이렇게 출력하면 기존의 표기법으로 출력이 가능하다.
```py
# 1. 표본 데이터의 평균
print(df['Caffeine(mg)'].mean()) # 94.264

# 2. Shapiro-Wilk의 p-value를 구하시오.
from scipy import stats
st, pv = stats.shapiro(df)
print(pv) # 0.9322031137746971 -> 귀무가설 채택 정규분포를 따름

# 3. 단일 표본 t-검정의 검정통계량과 p-value를 구하시오.
st, pv = stats.ttest_1samp(df['Caffeine(mg)'], 95, alternative='less')
print(st, '{:.10f}'.format(pv)) # -5.501737036221897 0.0000058687

# 4. 유의 수준 0.05하에서 귀무가설을 기준으로 검정의 결과를 (채택/기각)중 선택하여 입력하시오.
# -> 귀무가설 기각
```

## 4-2. 독립표본 검정
- 개발된 충전기의 효과를 검정하기 위해 스마트폰 사용자 집단을 두 그룹으로 나누어 한 그룹에는 새로운 충전기를 제공하고, 나머지 그룹에는 기존의 충전기를 제공하였다. 그 후, 두 그룹의 평균 충전 완료 시간을 비교하였다. 두 그룹 모두 충전 시간은 정규분포를 따르며 분산은 같다고 가정한다...
- 정규성 검사와 등분산 검사는 할 필요가 없어졌다.
- new와 old의 충전시간들을 모은 열벡터를 전달하여 ttest를 진행하였다.
```py
from scipy import stats
# stats.ttest_ind()
cond1 = df['충전기'] == 'New'
cond2 = df['충전기'] == 'Old'

st, pv = stats.ttest_ind(df[cond1]['충전시간'], df[cond2]['충전시간'], alternative='less')

print(st, '{:.10f}'.format(pv)) # -4.582575694955849 0.0001154655 -> 귀무가설 기각
```

## 4-3. 대응표본검정
- 왜 표본평균을 따로 구하라고 할까?
- 가설 검정 통계량 t는 이렇게 생겼기 때문:
- t = (d̄ − μd) / (s_d / √n)
- 구성 요소를 보면:
- d̄ = 표본평균(직접 계산)
- μd = 가설 속 값 (H0에서 μd = 0)
- s_d = 표본 표준편차
- n = 표본 수
- 즉, t 값을 구하려면 표본평균 d̄이 반드시 필요하다.
- μd = (새로운 교수 방법 – 기존 교수 방법)의 모평균이다.
- 대응표본검정은 모평균이 0이라고 가정했을때 검정통계량으로 t분포위에 올려서 판단하는 것
```py
# 1.μd의 표본평균을 구하시오.
df['diff'] = df['새로운방법'] - df['기존방법']
df['diff'].mean() # -1.0300000000000005

# 2. 위의 가설을 검정하기 위한 검정 통계량과 p-value를 구하시오.
from scipy import stats
st, pv = stats.ttest_rel(df['새로운방법'], df['기존방법'], alternative='less')
print(st, '{:.10f}'.format(pv)) # -3.407973078114844 0.0038872633 -> 귀무가설 기각
```