# 📌 1. K-means 군집화의 한계와 DBSCAN의 개념

## 1-1. 군집이란 무엇인가

- **군집(Cluster)**: 비슷한 성질을 가진 데이터 포인트들이 모여 있는 집단이다.  
- 군집화(Clustering)는 데이터에 라벨이 없는 상태에서 **비슷한 것끼리 묶어 데이터의 숨겨진 구조를 찾는 과정**이다.
- 예시:  
  - 고객 데이터를 군집화 → 소비 패턴이 비슷한 집단  
  - 환자 데이터를 군집화 → 증상·반응이 유사한 환자 집단  
  - 유전자 데이터를 군집화 → 발현 패턴이 유사한 그룹

---

## 1-2. K-means의 작동 원리와 전제

- K-means는 “**중심점(centroid)에서 가장 가까운 점들끼리 묶는다**”는 거리 기반 알고리즘이다.
- 과정:
  1. K개의 중심을 임의로 지정
  2. 각 점을 가장 가까운 중심에 할당
  3. 각 군집의 평균으로 중심 재계산
  4. 할당이 변하지 않을 때까지 반복
- 전제 조건:
  - 군집이 **구형**에 가깝고
  - **크기와 밀도**가 비슷하며
  - **거리가 기준**이 되어도 경계가 왜곡되지 않는 경우

---

## 1-3. 크기와 밀도가 다르면 문제가 생기는 이유

- 현실 데이터는 다음과 같은 경우가 많다:
  - A 군집: 작고 조밀
  - B 군집: 크고 희박
- 이때 K-means는 거리 기준만 보기 때문에:
  - 희박한 군집의 일부 점을 잘못된 군집에 할당하거나  
  - 중심이 치우쳐 군집 경계가 왜곡된다.
- 즉, **데이터의 실제 구조(자연스러운 그룹)**를 제대로 반영하지 못한다.

✅ 핵심: “정답(라벨)”을 못 찾는다는 말보다 **데이터의 진짜 구조를 파악하지 못한다**고 이해하는 것이 정확하다.

---

## 1-4. DBSCAN의 개념과 K-means와의 차이

- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: 밀도를 기준으로 군집을 찾는 알고리즘
- 핵심 아이디어:
  - 일정 반경(ε) 안에 최소 개수(MinPts) 이상의 점이 있으면 군집의 중심(core)로 간주  
  - 이웃 점들을 계속 연결하여 밀집 영역을 확장  
  - 밀도가 낮은 점은 노이즈로 처리
- 특징 비교:

| 항목 | K-means | DBSCAN |
|------|--------|--------|
| 기준 | 평균까지 거리 | 밀도 |
| 군집 형태 | 구형에 적합 | 임의의 형태도 가능 |
| 크기/밀도 | 비슷해야 잘 작동 | 달라도 잘 작동 |
| 군집 개수 | K를 미리 지정 | 자동 결정 |
| 이상치 | 군집 중 하나에 포함됨 | 노이즈로 분리 가능 |

---

## 1-5. 핵심 요약

- K-means는 **“평균에서 가까운 것끼리 묶기”**라는 단순한 규칙 때문에,  
  **군집 크기나 밀도가 크게 다르면 데이터의 실제 구조를 제대로 찾지 못한다.**
- DBSCAN은 밀도를 기준으로 군집을 찾기 때문에 **군집의 크기·밀도가 달라도 자연스러운 구조를 잘 포착**한다.
- 따라서 데이터 구조가 복잡하거나 이상치가 존재하는 상황에서는 DBSCAN이 더 유용하다.

<br>
<br>
<br>

# 📌 2. 군집분석, 랜덤포레스트 등

---

## 2-1. K-means 군집화의 한계와 개념

**1) 군집(Cluster)의 의미**  
군집이란 유사한 특성을 가진 데이터들의 자연스러운 집합이다. 군집화란 라벨이 없는 상태에서 비슷한 데이터끼리 묶는 비지도 학습(unsupervised learning) 방법이다.

**2) K-means의 한계**  
K-means는 각 점을 "가장 가까운 중심(centroid)"에 할당하며, 각 군집의 평균을 중심으로 업데이트한다.  
하지만 군집의 크기나 밀도가 다르면 문제가 생긴다.

- 큰 군집과 작은 군집이 함께 있을 경우 큰 군집에 끌려 중심이 왜곡된다.
- 밀도가 높은 집단과 희박한 집단이 섞여 있으면 희박한 집단이 잘못 분류된다.

이는 결국 K-means가 **"평균과 거리"만으로 판단하기 때문**이다.

---

## 2-2. 계층적 군집분석

**1) 정의**  
계층적 군집분석은 데이터를 계층적으로 묶어나가며 트리를 만드는 군집 방법이다. K를 미리 정할 필요 없이 덴드로그램(dendrogram)에서 원하는 군집 수를 선택한다.

**2) 주요 연결 방법**  
- **단일 연결법(Single Linkage):** 군집 간 가장 가까운 거리 사용. 이상치에 민감하고 길쭉한 군집 생성 가능.  
- **완전 연결법(Complete Linkage):** 군집 간 가장 먼 거리 사용. 군집이 더 조밀하고 균일해진다.  
- **평균 연결법(Average Linkage):** 두 군집 간 평균 거리를 사용. 단일·완전 연결법의 중간 성질.  
- **와드 연결법(Ward’s Method):** 군집 병합 시 SSE(제곱합) 증가가 최소화되도록 병합. 분산을 최소화하는 가장 안정적인 방법이다.

---

## 2-3. PCA를 이용한 이상치 탐지

주성분 분석(PCA)은 고차원 데이터를 저차원으로 투영해 주요 패턴을 찾는 방법이다. 이상치는 주성분 공간에서 대부분의 데이터가 모여 있는 패턴을 따르지 않는 점을 의미한다.  
즉, PCA를 사용하면 데이터의 주된 변동성에서 벗어나는 관측치를 **이상치(outlier)** 로 식별할 수 있다.

---

## 2-4. Apriori 알고리즘

**1) 정의**  
Apriori는 연관규칙 분석(Association Rule Mining)에서 자주 등장하는 항목집합을 찾는 알고리즘이다.  
예: 장바구니 분석에서 “우유를 산 사람은 빵을 살 확률이 높다” 같은 규칙을 찾는다.

**2) 핵심 아이디어**  
- 자주 등장하는 작은 집합이 자주 등장하는 큰 집합의 부분집합이다.  
- 따라서 작은 집합부터 점차 확장하며 자주 등장하는 집합만 탐색한다.

---

## 2-5. 비정상 시계열의 정상화

비정상 시계열을 정상 시계열로 만드는 목적은 **평균과 분산이 일정한 상태에서 분석**하기 위함이다.  
이를 위해 차분(differencing), 로그 변환(log transform), 계절성 제거 등을 사용한다.

**정규화(normalization)**는 데이터의 스케일을 조정할 뿐, 시간 흐름에 따른 평균·분산의 변화(비정상성)는 제거하지 못하므로 정상화 방법으로 적절하지 않다.

---

## 2-6. 랜덤포레스트와 지니계수

**1) 지니 불순도(Gini Impurity)**  
결정트리에서 노드의 "순도"를 나타내는 지표이다.

- 공식: G = 1 - Σ(pᵢ²)  
- pᵢ: 노드에서 클래스 i의 비율

**2) 해석**  
- G = 0 → 완전히 한 클래스(순수)  
- G ↑ → 여러 클래스가 섞여 있음(불순)

트리는 불순도를 크게 줄이는(split 후 G 감소가 큰) 변수를 선택하여 분할한다.

---

## 2-7. K-means에서 군집 개수(K) 결정과 WCSS

K는 알고리즘이 자동으로 찾지 못하는 하이퍼파라미터이므로 사용자가 직접 정해야 한다.  
이를 위해 **집단 내 제곱합(WCSS)**을 활용한다.

- 공식: WCSS = Σ Σ || xᵢ - μₖ ||²  
- 각 군집 내 데이터가 중심과 얼마나 가까운지 나타낸다.

K를 늘릴수록 WCSS는 감소하지만, 어느 시점부터 감소 폭이 급격히 줄어든다.  
이때의 “팔꿈치(Elbow)” 지점이 최적 K의 후보이다.

---

✅ 요약  
- 군집화: 비슷한 특성을 가진 데이터끼리 묶기  
- K-means: 평균 거리 기반, 크기·밀도 차이에는 취약  
- 계층적 군집: 트리 구조로 군집화  
- PCA: 이상치를 주성분 공간에서 탐지  
- Apriori: 연관 규칙 탐색 알고리즘  
- 비정상 시계열 → 정상화는 차분·로그 등으로  
- 지니계수: 노드 불순도, 분류기준  
- WCSS: 군집 응집력 지표, Elbow 기법으로 K 결정
