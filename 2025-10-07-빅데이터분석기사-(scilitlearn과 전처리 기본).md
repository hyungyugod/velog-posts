# ğŸ“Œ 1. scikit-learn ì£¼ìš” ëª¨ë“ˆ

| ë¶„ë¥˜ | ëª¨ë“ˆëª… | ì„¤ëª… | ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ ë° ê¸°ëŠ¥ |
|------|---------|------|----------------------|
| **ë³€ìˆ˜ ì²˜ë¦¬** | `sklearn.preprocessing` | ë°ì´í„° ì „ì²˜ë¦¬ì— ê´€í•œ ê¸°ëŠ¥ ì œê³µ | í‘œì¤€í™”, ì •ê·œí™”, ì›-í•« ì¸ì½”ë”© ë“± |
| **ë°ì´í„° ë¶„ë¦¬Â·ê²€ì¦** | `sklearn.model_selection` | ë°ì´í„° ë¶„í•  ë° êµì°¨ ê²€ì¦ ë“± ë‹¤ì–‘í•œ ê²€ì¦ ë°©ë²• ì œê³µ | í•™ìŠµìš©/í…ŒìŠ¤íŠ¸ìš© ë¶„ë¦¬, êµì°¨ê²€ì¦(K-Fold), GridSearchCV ë“± |
| **í‰ê°€** | `sklearn.metrics` | ë¶„ë¥˜Â·íšŒê·€ ë“±ì˜ ëª¨ë¸ í‰ê°€ ì§€í‘œ ì œê³µ | Accuracy, Precision, Recall, F1, ROC-AUC, RMSE ë“± |
| **ì§€ë„í•™ìŠµ** | `sklearn.linear_model` | ì„ í˜•íšŒê·€ ë° ë¡œì§€ìŠ¤í‹± íšŒê·€ ì•Œê³ ë¦¬ì¦˜ ì œê³µ | Linear Regression, Logistic Regression ë“± |
|  | `sklearn.svm` | ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ì•Œê³ ë¦¬ì¦˜ ì œê³µ | SVM, SVR ë“± |
|  | `sklearn.neighbors` | ì¸ì ‘ ì´ì›ƒ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ ì œê³µ | KNN (K-Nearest Neighbors) |
|  | `sklearn.tree` | ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì•Œê³ ë¦¬ì¦˜ ì œê³µ | Decision Tree |
|  | `sklearn.ensemble` | ì•™ìƒë¸” í•™ìŠµ ê¸°ë²• ì œê³µ | ëœë¤ í¬ë ˆìŠ¤íŠ¸, ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë“± |
| **ë¹„ì§€ë„í•™ìŠµ** | `sklearn.cluster` | êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ ì œê³µ | K-Means, í‰ê· ì´ë™, DBSCAN ë“± |

<br>

# ğŸ“Œ 2. scikit-learn ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ ìš”ì•½

| ì•Œê³ ë¦¬ì¦˜ | ì†Œì† ëª¨ë“ˆ | ê°„ë‹¨í•œ ì„¤ëª… |
|-----------|-------------|--------------|
| **StandardScaler (í‘œì¤€í™”)** | `sklearn.preprocessing` | í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ì—¬ ëª¨ë¸ í•™ìŠµ ì•ˆì •ì„±ì„ ë†’ì„ |
| **MinMaxScaler (ì •ê·œí™”)** | `sklearn.preprocessing` | ë°ì´í„°ë¥¼ 0~1 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ í¬ê¸° ì°¨ì´ë¥¼ ì¤„ì„ |
| **OneHotEncoder (ì›-í•« ì¸ì½”ë”©)** | `sklearn.preprocessing` | ë²”ì£¼í˜• ë°ì´í„°ë¥¼ 0ê³¼ 1ì˜ ì´ì§„ ë²¡í„°ë¡œ ë³€í™˜í•¨ |
| **train_test_split** | `sklearn.model_selection` | ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• í•¨ |
| **KFold / StratifiedKFold(ë¹„ìœ¨ìœ ì§€)** | `sklearn.model_selection` | êµì°¨ê²€ì¦ì„ ìˆ˜í–‰í•´ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•¨ |
| **GridSearchCV** | `sklearn.model_selection` | í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ìë™ìœ¼ë¡œ íƒìƒ‰í•´ ìµœì ì˜ ëª¨ë¸ì„ ì°¾ìŒ |
| **accuracy_score / precision_score / recall_score** | `sklearn.metrics` | ë¶„ë¥˜ ëª¨ë¸ì˜ ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ì„ í‰ê°€í•¨ |
| **f1_score / roc_auc_score** | `sklearn.metrics` | ëª¨ë¸ì˜ ì¢…í•©ì  ì„±ëŠ¥ê³¼ ROC ê³¡ì„  ì•„ë˜ ë©´ì (AUC)ì„ ê³„ì‚°í•¨ |
| **mean_squared_error / r2_score** | `sklearn.metrics` | íšŒê·€ ëª¨ë¸ì˜ ì˜¤ì°¨ í¬ê¸° ë° ì„¤ëª…ë ¥(RÂ²)ì„ í‰ê°€í•¨ |
| **LinearRegression** | `sklearn.linear_model` | ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ í•™ìŠµí•¨ |
| **LogisticRegression** | `sklearn.linear_model` | ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì„ í˜• ëª¨ë¸, í™•ë¥ ì  ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•¨ |
| **SVM (Support Vector Machine)** | `sklearn.svm` | ì´ˆí‰ë©´ì„ ì´ìš©í•´ ë°ì´í„°ë¥¼ êµ¬ë¶„í•˜ëŠ” ë¶„ë¥˜/íšŒê·€ ì•Œê³ ë¦¬ì¦˜ |
| **SVR (Support Vector Regression)** | `sklearn.svm` | SVM ê°œë…ì„ íšŒê·€ ë¬¸ì œì— ì ìš©í•œ ì•Œê³ ë¦¬ì¦˜ |
| **KNN (K-Nearest Neighbors)** | `sklearn.neighbors` | ê°€ì¥ ê°€ê¹Œìš´ Kê°œì˜ ë°ì´í„°ë¡œë¶€í„° ë‹¤ìˆ˜ê²°ë¡œ ì˜ˆì¸¡í•¨ |
| **DecisionTreeClassifier / Regressor** | `sklearn.tree` | ë°ì´í„°ë¥¼ ë¶„í• í•´ ì˜ˆì¸¡ ê·œì¹™ì„ ìƒì„±í•˜ëŠ” íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ |
| **RandomForestClassifier / Regressor** | `sklearn.ensemble` | ì—¬ëŸ¬ ê²°ì •íŠ¸ë¦¬ë¥¼ ì¡°í•©í•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì•™ìƒë¸” í•™ìŠµ |
| **GradientBoosting** | `sklearn.ensemble` | ì´ì „ ëª¨ë¸ì˜ ì˜¤ì°¨ë¥¼ ë³´ì™„í•˜ë©° ë‹¨ê³„ì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë¶€ìŠ¤íŒ… ê¸°ë²• |
| **AdaBoost** | `sklearn.ensemble` | ì•½í•œ ë¶„ë¥˜ê¸°ë¥¼ ê²°í•©í•˜ì—¬ ê°•ë ¥í•œ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“œëŠ” ë¶€ìŠ¤íŒ… ë°©ë²• |
| **KMeans** | `sklearn.cluster` | ë¹„ì§€ë„í•™ìŠµ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜, ë°ì´í„°ë¥¼ Kê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ” |
| **MeanShift** | `sklearn.cluster` | ë°ì´í„°ì˜ ë°€ì§‘ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ìœ¼ë¡œ êµ°ì§‘ ì¤‘ì‹¬ì„ ì°¾ìŒ |
| **DBSCAN** | `sklearn.cluster` | ë°€ë„ ê¸°ë°˜ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ë…¸ì´ì¦ˆì™€ ì´ìƒì¹˜ë¥¼ êµ¬ë¶„í•¨ |

# ğŸ“Œ 3. scikit-learnì™€ ë°ì´í„° ì „ì²˜ë¦¬
### 3-1. ê¸°ì›
- SciPy (Scientific Python): ìˆ˜í•™, ê³¼í•™, ê³µí•™ ê³„ì‚°ì„ ìœ„í•œ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤.
- scikit-learnì€ SciPyì˜ í™•ì¥ íŒ¨í‚¤ì§€(â€œsci-kitâ€) ì¤‘ í•˜ë‚˜ë¡œ ì‹œì‘ë˜ì—ˆë‹¤.
- scikit-image â†’ ì´ë¯¸ì§€ ì²˜ë¦¬ìš©
- scikit-bio â†’ ìƒë¬¼ì •ë³´í•™ìš©
- scikit-learn â†’ ë¨¸ì‹ ëŸ¬ë‹ìš©

| êµ¬ì„± ìš”ì†Œ     | ì˜ë¯¸                       | ì„¤ëª…                                                                                           |
| --------- | ------------------------ | -------------------------------------------------------------------------------------------- |
| **sci-**  | science (ê³¼í•™)             | ê³¼í•™ì  ê³„ì‚°, ì¦‰ **scientific computing**ì„ ì˜ë¯¸í•¨. Pythonì—ì„œ NumPy, SciPyì™€ ê°™ì€ ê³¼í•™ ì—°ì‚°ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì ‘ë‘ì–´ë¡œ ìì£¼ ì“°ì„. |
| **-kit**  | toolkit (ë„êµ¬ìƒì)           | ì—¬ëŸ¬ ê¸°ëŠ¥ì„ í•˜ë‚˜ë¡œ ë¬¶ì€ **í™•ì¥ íŒ¨í‚¤ì§€**ë¥¼ ëœ»í•¨. ì¦‰, SciPyë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ â€œí™•ì¥ ë„êµ¬ ëª¨ìŒâ€ì´ë¼ëŠ” ì˜ë¯¸.                          |
| **learn** | machine learning (ê¸°ê³„ í•™ìŠµ) | ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•µì‹¬ ê¸°ëŠ¥ì¸ **ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„**ì„ ë‚˜íƒ€ëƒ„.                                                         |

### 3-2. ë°ì´í„° ì „ì²˜ë¦¬ ì¤€ë¹„
- x = df.drop(['grade'], axis = 1) 'grade'ë¼ëŠ” ì—´ì„ ì‚­ì œí•œ ë³€ìˆ˜ë¥¼ ë…ë¦½ë³€ìˆ˜(ì„¤ëª…ë³€ìˆ˜) xë¡œ ë‘”ë‹¤.
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ì…ë ¥ê°’ X â†’ ì˜ˆì¸¡ê°’ yÌ‚ì„ ë°°ìš°ëŠ” êµ¬ì¡°ì´ë‹¤. ì¦‰, ëª¨ë¸ì€ Xë¥¼ ë³´ê³  yë¥¼ ì˜ˆì¸¡í•˜ë ¤ê³  í•œë‹¤.
- ê·¸ë˜ì„œ ì‹¤ì œë¡œ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¬ ë•ŒëŠ”
- X: ëª¨ë¸ì´ ê´€ì°°í•  ì—¬ëŸ¬ ì •ë³´ (ì…ë ¥ íŠ¹ì§•ë“¤)
- y: ê·¸ ì •ë³´ë¡œë¶€í„° ì˜ˆì¸¡í•´ì•¼ í•  ê°’ (ì •ë‹µ) ì´ë ‡ê²Œ ë‚˜ëˆ„ëŠ” ê²Œ í•„ìˆ˜ì´ë‹¤.
```py
import pandas as pd
import numpy as np

df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/data/main/dat.csv')

x = df.drop(['grade'], axis = 1)
y = df.grade
```

### 3-3. ë°ì´í„° ë¶„í•  - ë‹¨ìˆœ ë¬´ì‘ìœ„ ìƒ˜í”Œë§ (sklearn.model_selection from train_test_split)
- train, testì˜ ë¹„ìœ¨ì„ ì„¤ì •í•œ ë’¤ì— ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ í• ë‹¹í•˜ëŠ” ë°©ë²• (ë³´í†µ 8:2, 7:3ìœ¼ë¡œ ë¶„í• )
- ë§Œì•½ ë°ì´í„°ê°€ ì¹˜ìš°ì³ìˆë‹¤ë©´ ëœë¤ ìƒ˜í”Œë§ì´ë”ë¼ë„ ê·¸ ì¹˜ìš°ì¹¨ì„ ìœ ì§€í•˜ê²Œ ë˜ë¯€ë¡œ ì£¼ì˜í•´ì•¼í•œë‹¤.
- (292,) : 292ê°œì˜ ì›ì†Œê°€ ìˆì§€ë§Œ, ì—´(column) ì°¨ì›ì´ ë”°ë¡œ ì—†ëŠ” 1ì°¨ì› ë°°ì—´ì´ë¼ëŠ” ëœ» -> 1ì—´ì€ ìƒëµ
- random_state ê°’ì„ 0 (ë˜ëŠ” ì–´ë–¤ ìˆ«ìë“  ë™ì¼)ìœ¼ë¡œ ì£¼ë©´ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë‚œìˆ˜ê°€ ê³ ì •ë˜ì–´ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.
- shuffle = True -> ë°ì´í„°ë¥¼ ì„ì–´ì„œ trainê³¼ testë¡œ ë¶„í• í•œë‹¤. 
- True â†’ ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì€ ë’¤ ë‚˜ëˆ”
- False â†’ ìˆœì„œëŒ€ë¡œ ì•ë¶€ë¶„ì€ train, ë’·ë¶€ë¶„ì€ testë¡œ ë‚˜ëˆ”
- xx,yyìˆœìœ¼ë¡œ í• ë‹¹ ë°›ì•„ì•¼í•œë‹¤.
```py
from sklearn.model_selection import train_test_split
train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.2,random_state = 0, shuffle = True, stratify = None)
```

### 3-4. ë°ì´í„° ë¶„í•  - ì¸µí™” ìƒ˜í”Œë§
- ê° ë²”ì£¼ë³„ë¡œ ë‹¨ìˆœë¬´ì‘ìœ„ ìƒ˜í”Œë§ì„ í•œ í›„ì— ê²°í•©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ì…‹ì„ ë²”ì£¼ì˜ ë¹„ìœ¨ì— ë§ê²Œ ë¶„í• í•œë‹¤.
- stratify=df['school']ë¡œ ë¹„ìœ¨ì„ ìœ ì§€í•  ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì„ ì»¬ëŸ¼ì„ ì§€ì •í•œë‹¤.
- value_counts()ë¥¼ í†µí•´ ê° ë²”ì£¼ì˜ ì†ì„±ê°’ ë¹„ìœ¨ì„ ë°”ë¡œ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë‹¤.
- ë˜ seabornì˜ countplotì„ í™œìš©í•˜ì—¬ ì´ ë¹„ìœ¨ì„ ì‹œê°í™”í•´ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```py
import seaborn as sns

train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0, shuffle=True, stratify=df['school'])

train_x['school'].value_counts(normalize=True)
sns.countplot(train_x, x='school')
```

### 3-5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ - í‰ê· ê°’, ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ëŒ€ì¹˜ (SimpleImputer)
- df.isna().sum() ë¡œ ê²°ì¸¡ì¹˜ê°€ ì–´ë””ì— ì¡´ì¬í•˜ëŠ”ì§€ ë¹ ë¥´ê²Œ í™•ì¸í•œ í›„ ì–´ë–»ê²Œ ì²˜ë¦¬í• ì§€ ê²°ì •í•œë‹¤.
- impute (ë™ì‚¬) â†’ â€œì–´ë–¤ ì›ì¸ì´ë‚˜ ì±…ì„ì„ ~ì—ê²Œ ëŒë¦¬ë‹¤(assign or attribute something to someone)â€
- ì¦‰, â€œë¬´ì–¸ê°€ì˜ ì´ìœ ë‚˜ ê°’ì„ ì¶”ì •í•´ì„œ ì±„ì›Œë„£ê±°ë‚˜ ì±…ì„ì„ ì „ê°€í•˜ë‹¤.â€ ë°ì´í„° ê³¼í•™ì—ì„œëŠ” ì´ëŠ” ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•˜ë‹¤ ë¼ëŠ” ë§ê³¼ ê°™ë‹¤.
- df['col'] ì€ ë‚´ë¶€ì ìœ¼ë¡œ __getitem__ ë©”ì„œë“œê°€ ë‹¨ì¼ Keyë¥¼ ë°›ì•˜ì„ ë•Œ Seriesë¥¼ ë°˜í™˜í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆê³ ,
- df[['col']] ì€ Keyë¥¼ **ë¦¬ìŠ¤íŠ¸(list)**ë¡œ ë°›ì•˜ê¸° ë•Œë¬¸ì— ê·¸ ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì—¬ëŸ¬ ì—´ì„ DataFrame í˜•íƒœë¡œ ë°˜í™˜í•˜ë„ë¡ ë˜ì–´ ìˆë‹¤.
- scikit-learn ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ 2D ë°°ì—´ í˜•íƒœë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì— ê°’ì„ ë„˜ê²¨ì¤„ë•Œ 2ì°¨ì› ë°°ì—´ë¡œ ë„˜ê²¨ì£¼ì–´ì•¼í•¨ì„ ìœ ì˜í•´ì•¼í•œë‹¤.
- scikit-learnì˜ ê±°ì˜ ëª¨ë“  ë³€í™˜ê¸°(ì˜ˆ: SimpleImputer, StandardScaler, MinMaxScaler)ê°€ ë”°ë¥´ëŠ” ê³µí†µ íŒ¨í„´ì¸ it(), transform(), fit_transform()ì— ëŒ€í•´ì„œë„ ì•Œ í•„ìš”ê°€ ìˆë‹¤. ì´ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

| ë©”ì„œë“œ                 | ì—­í•                                      | ë¹„ìœ                     |
| ------------------- | -------------------------------------- | --------------------- |
| **fit()**           | ë°ì´í„°ì˜ **í†µê³„ì  íŠ¹ì„±(í‰ê· , ë¶„ì‚°, ì¤‘ì•™ê°’ ë“±)** ì„ â€œí•™ìŠµâ€í•¨ | â€œê¸°ì¤€ì„ ë°°ìš°ëŠ” ë‹¨ê³„â€          |
| **transform()**     | ë°°ìš´ ê¸°ì¤€ì„ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ë¥¼ **ë³€í™˜**í•¨               | â€œë°°ìš´ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°”ê¾¸ëŠ” ë‹¨ê³„â€ |
| **fit_transform()** | ìœ„ ë‘ ë‹¨ê³„ë¥¼ í•œ ë²ˆì— ìˆ˜í–‰ (fit + transform)      | â€œë°°ìš°ê³  ë°”ë¡œ ì ìš©í•˜ê¸°â€         |

- í•˜ì—¬ ì²˜ìŒì— fit()ì„ í†µí•´ ê¸°ì¤€ì„ í•™ìŠµí•˜ê³  ì´í›„ì—ëŠ” fití•œ ê¸°ì¤€ì— ë”°ë¼ transformì„ ìˆ˜í–‰í•˜ê¸°ë§Œ í•˜ë©´ ëœë‹¤.
- ë˜í•œ ì›ë³¸ì„ í›¼ì†í•˜ì§€ ì•Šê³  ì—¬ëŸ¬ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ ì‹œí—˜í•´ë³´ê¸° ìœ„í•´ copy()ë¥¼ í†µí•´ ê¹Šì€ ë³µì‚¬ë¥¼ ìˆ˜í–‰í•œë‹¤.
```py
from sklearn.impute import SimpleImputer

imputer_mean = SimpleImputer(strategy = 'mean')
train_x1 = train_x.copy()
test_x1 = test_x.copy()

train_x1['goout'] = imputer_mean.fit_transform(train_x1[['goout']])
test_x1['goout'] = imputer_mean.transform(test_x1[['goout']])
```
- ì´ë•Œ strategyë¥¼ medianìœ¼ë¡œ í•˜ë©´ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì¹˜ë˜ê³  most_frequentë¡œ í•˜ë©´ ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì¹˜ë˜ëŠ” ë³€í™˜ê¸° ê°ì²´ë¥¼ ìƒì„±í•´ë‚¼ ìˆ˜ ìˆë‹¤.

### 3-6. ê²°ì¸¡ê°’ ì²˜ë¦¬ - KNN ëŒ€ì¹˜ë²• (KNNImputer) 
- KNNì€ ì§€ë„í•™ìŠµ(Supervised Learning) ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì–´ë–¤ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ, ê·¸ ì£¼ë³€ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ Kê°œì˜ ë°ì´í„°ë¥¼ ë³´ê³ , ë‹¤ìˆ˜ê°€ ì†í•œ ê·¸ë£¹(í´ë˜ìŠ¤)ì„ ë”°ë¼ê°€ë„ë¡ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ê²ƒì´ë‹¤.
- ì´ë¥¼ ê²°ì¸¡ê°’ ì±„ìš°ê¸°ì— ì‚¬ìš©í•œë‹¤ë©´ ê²°ì¸¡ê°’ì´ ìˆëŠ” ë°ì´í„°ì˜ ë‹¤ë¥¸ ì†ì„±ë“¤ê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì„œ ê°€ì¥ ê°€ê¹Œìš´ Kê°œì˜ ìƒ˜í”Œì„ ì°¾ê³ , ê·¸ ìƒ˜í”Œë“¤ì˜ í•´ë‹¹ ì†ì„± í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤.
- ë”°ë¼ì„œ KNN ê¸°ë°˜ ê²°ì¸¡ê°’ ëŒ€ì¹˜(KNNImputer)ëŠ” â€œê±°ë¦¬(distance)â€ ë¥¼ ê³„ì‚°í•´ì„œ ì‘ë™í•˜ê¸°ë•Œë¬¸ì— ìˆ«ìí˜• ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
- í•˜ì—¬ ìš°ì„  ë°ì´í„°ì…‹ì„ select_dtypes í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ number íƒ€ì…ê³¼ objectë¡œ ë¶„ë¦¬í•´ë‘ê³  KNNImputerë¡œ ê²°ì¸¡ê°’ì„ ëŒ€ì¹˜í•œ ë‹¤ìŒì— ë‚˜ì¤‘ì— pd.concatì„ í†µí•´ í•©ì³ ì£¼ì–´ì•¼í•œë‹¤.
- ì´ë•Œ ëŒ€ì¹˜í•œ ê²°ê³¼ê°’ì´ íŒë‹¤ìŠ¤ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë‚˜ì˜¤ë„ë¡ í•˜ë ¤ë©´ set_output(transform='pandas') ì˜µì…˜ì„ ì ìš©í•´ì£¼ì–´ì•¼í•œë‹¤.
- ë˜í•œ KNNImputer(n_neighbors=5) ìƒì„±ìì— n_neighbors=5ë¡œ ì°¸ê³ í•  ì£¼ë³€ ì´ì›ƒ ê°œìˆ˜ë¥¼ ì •í•´ì£¼ì–´ì•¼í•œë‹¤.
- ì´í›„ í•™ìŠµì„ ì§„í–‰í•˜ê³  (fit) ì´í›„ transformì„ í™œìš©í•˜ì—¬ ë³€í™˜í•œë‹¤.
```py
from sklearn.impute import KNNImputer

train_x2 = train_x.copy()
test_x2 = test_x.copy() 

train_x2_num = train_x2.select_dtypes('number')
test_x2_num = test_x2.select_dtypes('number')

train_x2_cat = train_x2.select_dtypes('object')
test_x2_cat = test_x2.select_dtypes('object')

imputer_knn = KNNImputer(n_neighbors=5).set_output(transform='pandas')
train_x2_num = imputer_knn.fit_transform(train_x2_num)
test_x2_num = imputer_knn.transform(test_x2_num)

train_x2 = pd.concat([train_x2_num, train_x2_cat], axis=1)
test_x2 = pd.concat([test_x2_num, test_x2_cat], axis=1)

train_x2.head()
```