# 📌 1. Cronbach’s α = .71 의 의미

## 1-1. Cronbach’s α가 뭐하는 지표인지

- Cronbach’s α는 **내적 일관성(internal consistency)**, 즉  
  “여러 문항이 **같은 개념(잠재 특성)** 을 얼마나 일관되게 측정하고 있는가”를 나타내는 신뢰도 지표다.
- 예: ‘스트레스’라는 하나의 개념을 5개 문항으로 물을 때,
  응답자들이 이 5문항에 일관된 패턴으로 응답하면 → α가 커진다.

일반적인 해석 기준(엄밀한 법칙은 아니고 관행에 가까운 기준):

- $α \ge 0.9$: 너무 높음(문항 중복 가능성)
- $0.8 \le α < 0.9$: 높음
- $0.7 \le α < 0.8$: **양호한 신뢰도**
- $0.6 \le α < 0.7$: 조금 애매, 보완 필요
- $α < 0.6$: 낮은 신뢰도

따라서  
**“Cronbach’s α = .71”** 은  
문항들이 “같은 개념을 꽤 일관되게 측정하고 있다” → **실무에서 보통 ‘신뢰도 양호’** 라고 쓸 수 있는 수준이다.

---

## 1-2. Cronbach’s α 식 구조

대표적인 공식은 아래와 같다.

- 문항 수가 $k$개일 때:

$ \alpha = \dfrac{k}{k - 1} \left( 1 - \dfrac{\sum_{i=1}^{k}s_i^2}{s_T^2} \right) $

- $k$: 문항 개수  
- $s_i^2$: 문항 $i$의 분산  
- $s_T^2$: 여러 문항을 합친 **총점**의 분산

핵심 구조:

- 분자 부분 $ \sum s_i^2 $: 각 문항이 따로따로 변하는 정도의 합
- 분모 $ s_T^2 $: “문항들을 합쳐서 만든 점수”가 사람들 사이에서 얼마나 다양하게 흩어져 있는지(총점의 분산)
- 문항들이 서로 잘 연관되어 있으면  
  → 공분산이 커져서 $s_T^2$가 커지고  
  → $\sum s_i^2 / s_T^2$ 비율이 작아져서  
  → $1 - (\sum s_i^2 / s_T^2)$, 즉 $α$가 커진다.

---

## 1-3. 왜 “문항 간 상관”과 연결되는지

총점의 분산은 이렇게 쓸 수 있다.

$ s_T^2 = \sum_{i=1}^{k} s_i^2 + 2 \sum_{i<j} \text{cov}(i,j) $

여기서 $\text{cov}(i,j)$는 문항 $i$와 $j$의 공분산이다.

- 문항들이 서로 비슷하게 움직이면(상관 높음)  
  → 공분산 항이 커지고  
  → $s_T^2$가 커진다.
- 반면 $\sum s_i^2$ 는 “각 문항 혼자 변하는 양”만 모은 값이므로 그대로.
- 그러면 $\sum s_i^2 / s_T^2$ 비율은 작아지고, 결국 $α$가 커진다.

즉,  
**문항 간 상관이 높을수록 $α$는 커진다**  
→ 내부 일관성이 높은 척도라고 해석한다.

---

## 1-4. p-value와의 관계

- Cronbach’s α는 **신뢰도(reliability)**,  
- p-value는 **통계적 유의성(significance)** 이라서 역할이 완전히 다르다.

$α$가 크다고 해서 p-value가 자동으로 유의해지는 것도 아니고,  
p-value가 유의하다고 해서 측정 도구의 신뢰도가 높은 것도 아니다.

따라서  
**“Cronbach’s α = .71이었다”** 는 내용은  
그냥 “이 척도는 어느 정도 일관되게 측정한다”는 말이고,  
**p-value와 직접적인 연결은 없다.**

---

# 📌 2. G*Power, 효과크기, 표본 수 계산

## 2-1. ANOVA에서의 효과크기 $f$ 와 “중간효과크기 .25”

ANOVA(분산분석)에서 효과크기 $f$는  
“집단 간 차이가 전체 변동 중 어느 정도 비율을 차지하느냐”를 나타내는 표준화된 지표다.

효과크기 $η^2$(에타제곱)을 이용해서

$ f = \sqrt{\dfrac{η^2}{1 - η^2}} $

Cohen이 제시한 기준(대략):

- 작은 효과: $f = 0.10$ (대략 $η^2 \approx 0.01$)
- **중간 효과: $f = 0.25$ (대략 $η^2 \approx 0.06$)**
- 큰 효과: $f = 0.40$ (대략 $η^2 \approx 0.14$)

즉, **중간효과크기 $0.25$** 라는 말은  
“집단 간 차이가 전체 변동의 약 6% 정도를 설명할 정도로 존재한다”는 수준을 가정하는 것이다.  

이건 **F값(검정통계량)이 0.25라는 뜻이 아니다.**  
$F$는 실제 데이터에서 계산되는 값이고,  
$f$는 그 $F$에서 유도된 “관계의 강도”를 표준화한 값이다.

---

## 2-2. G*Power로 표본 수를 구할 때 쓰는 정보들

연구에서 G*Power 3.1로 ANOVA(집단 수 4개)를 설계한다고 하자.  
입력하는 값은 보통 이런 것들이다.

- 효과크기: $f = 0.25$ (중간 효과)  
- 유의수준: $\alpha = 0.05$  
- 검정력: $1 - \beta = 0.80$ (power 80%)  
- 집단 수: $k = 4$

이걸 입력하면 G*Power가 “최소 표본 수 $N$”을 계산해준다.  
예시 문장에서는 그 값이 **180명**으로 나온 상황이다.

의미:

> 진짜 효과크기가 $f = 0.25$ 정도이고,  
> 유의수준 5%, 검정력 80%, 집단 4개라고 가정하면,  
> **최소 180명 정도의 표본이 있어야 ‘차이를 제대로 잡아낼 힘’이 생긴다.**

---

## 2-3. “학년 당 50명, 총 200명, 탈락률 고려 220명” 해석

문장 구조를 뜯으면:

- 최소 필요 표본 수: $N_{\text{min}} = 180$
- 실제 설계:
  - 학년당 50명 × 4학년 = 200명
  - 여기에 **탈락률 10%** 고려 → $200 \times (1 + 0.1) = 220명 모집 계획
- 연구 결과: 실제 대상자 수가 220명 확보되었다고 하면,
  → “필요한 최소 표본수(180명)를 충족한다”라고 보고하는 것.

즉,

> 이 연구는  
> 통계적으로 중간 정도 효과를  
> 검정력 80%, 유의수준 .05로 탐지할 수 있을 만큼  
> 충분한 표본수를 확보했다.

라는 의미다.

---

# 📌 3. 이 것들이 “데이터 분석 프로세스”에서 차지하는 단계

## 3-1. 전체 흐름에서 위치

데이터 분석/연구 설계 전체를 대략 이렇게 볼 수 있다.

1. 연구 질문 설정  
2. 연구 설계 (변수, 집단 수, 척도 선택, 실험 구조 등)  
3. **표본 수 산출 (G*Power 등)**  
4. 데이터 수집  
5. **측정 도구 신뢰도 검증 (Cronbach’s α 등)**  
6. 데이터 정제(이상치·결측치), 기술통계  
7. 가설검정 (t-test, ANOVA, 회귀 등) → 여기서 p-value, F값 등장  
8. 결과 해석 및 보고

여기서:

- G*Power, 효과크기, 유의수준, 검정력 → **3. 설계 단계**
- Cronbach’s α → **5. 데이터 수집 후, 척도 신뢰도 확인 단계**
- F값, p값 → **7. 가설검정 단계**

---

## 3-2. 머신러닝 관점에서 대응시키면

- G*Power로 표본 수 계산  
  → “데이터가 얼마나 있어야 모델이 패턴을 안정적으로 배울 수 있나?”를 정량화한 것  
  → 학습곡선(learning curve) 감각과 비슷

- Cronbach’s α  
  → 여러 feature(문항)가 **같은 latent feature(잠재 특성)** 을 잘 반영하는지를 보는 것  
  → feature set의 품질(일관성) 체크

- 유의수준/검정력  
  → 분류 문제에서  
    - $\alpha$ ≈ False Positive Rate(FPR)에 대응  
    - power ≈ Recall(Sensitivity)에 대응

---

# 📌 4. Cronbach’s α 조금 더 깊게: 분산, 상관, 중복

## 4-1. “각 문항 분산 합이 작다 = 문항 간 연관이 높다”의 수학적 의미

다시 공식:

$ \alpha = \dfrac{k}{k - 1} \left( 1 - \dfrac{\sum s_i^2}{s_T^2} \right) $

또는

$ s_T^2 = \sum s_i^2 + 2 \sum_{i<j} \text{cov}(i,j) $

- 문항 간 상관이 높음 → 공분산이 커짐 → $s_T^2$ 커짐  
- $\sum s_i^2$는 각 문항의 개별 분산 합이라 그대로  
- 따라서 $\sum s_i^2 / s_T^2$ 비율이 작아지고, $α$가 커진다.

즉,

- “총점 분산에 비해 개별 분산 합이 상대적으로 작다” =  
- “총점의 분산이 대부분 공분산(문항 간 상관)에서 온다” =  
- “문항들이 서로 비슷하게 움직이고 있다” → 일관된 척도.

이게 바로 Cronbach’s α가 **“문항 간 상관이 높은가”** 를 보는 지표인 이유다.

---

## 4-2. 상관이 너무 높으면? 신뢰도 vs 중복

여기서 중요한 반전:

- 문항 간 상관이 너무 낮다 → $α$ 낮음 → “같은 개념도 아니네?”  
- **상관이 너무 높다(예: 0.8~0.9 이상)** → $α$는 매우 높게 나오지만  
  → 사실상 “같은 말을 여러 번 묻는 중복(item redundancy)”일 수 있다.

실무에서 자주 쓰는 감각:

- $α \approx 0.7 \sim 0.8$:  
  → “적당히 일관성 있으면서, 문항이 완전 중복은 아님”  
- $α \ge 0.9$:  
  → “신뢰도는 높지만 문항들이 거의 복붙 수준으로 비슷할 수 있음 → 일부 줄이는 것을 고려”

즉,  
**신뢰도(reliability)가 높다고 무조건 좋은 게 아니라,  
타당도(validity, 개념의 폭과 적합성)와 같이 봐야 한다.**

---

## 4-3. 왜 비슷한 문항을 여러 개 넣는가?

질문: “비슷한 문항이라면 하나만 물어보고, 서로 상관 없는 걸 여러 개 물어보는 게 정보량이 더 크지 않나?”

핵심 아이디어:

- 단일 문항은 **오차(노이즈)** 가 매우 크다.  
  - 그날 기분, 문장 해석, 응답자 피로, 편견이 응답에 영향을 준다.
- 비슷한 문항을 여러 개 물어보고 **합계나 평균을 쓰면**,  
  - 오차들은 서로 상쇄되고  
  - **공통된 부분(진짜 개념, latent trait)** 만 더 또렷해진다.

이건 모델 앙상블이랑 비슷하다.

- 하나의 불안정한 모델(문항 1개)보다  
- 비슷한 모델 여러 개(비슷한 문항들)를 평균내면 → 성능이 안정된다  
→ **신뢰도(reliability)** 상승.

반대로, 서로 상관이 너무 없는 문항들을 합쳐버리면:

- 각 문항이 서로 다른 개념을 측정  
- 합쳐놓으면 “이게 뭔 척도인지”가 모호해짐  
→ **타당도(validity)** 저하.

좋은 척도는:

- 문항 간 상관: 적당히 있음(보통 0.3~0.6 정도 선호)  
- 완전히 같지는 않고, 같은 개념의 다른 측면을 측정  
- 합치면 한 개념을 안정적으로 대표하는 점수가 된다.

---

## 4-4. 명목척도인데 α를 쓸 수 있나?

- 완전한 명목척도(순서가 아예 없는 값, 예: 혈액형, 성별)에 대해서는  
  분산, 공분산 개념이 애매하다 → Cronbach’s α를 그대로 쓰기 어렵다.
- 보통 설문 연구에서 α를 쓰는 문항들은 **리커트 척도(1~5점, 1~7점)** 와 같이  
  “명목처럼 보이지만 사실은 **서열 + 등간으로 간주하는 척도**”다.
  - 예: 1=전혀 아니다, 5=매우 그렇다 → ‘정도’가 있다.

진짜 이분형/명목형(예/아니오, 맞음/틀림 등)에는  
KR-20, KR-21 같은 **이분형 신뢰도 계수**를 쓰기도 한다.  
(KR-20은 Cronbach’s α의 특수 경우로 볼 수 있다.)

---

# 📌 5. ANOVA에서의 효과크기, F값, 표본 수

## 5-1. F값 vs 효과크기 $f$

- $F$: “집단 간 분산 ÷ 집단 내 분산” → 실제 데이터에서 계산되는 검정통계량  
- $f$: “집단 간 차이의 크기”를 표준화한 효과크기

둘은 관련 있지만 **동일한 값이 아니다**.

이 관계를 나타내는 식 중 하나는 (자유도를 포함해):

$ f^2 = \dfrac{F \cdot df_{\text{between}}}{df_{\text{within}} \cdot N} $

- 여기서 $df_{\text{between}}$: 집단 간 자유도  
- $df_{\text{within}}$: 집단 내 자유도  
- $N$: 전체 표본 수

즉, 같은 $F$라 해도 표본 수와 자유도에 따라 $f$는 달라진다.  
그래서 “효과크기 0.25”는 “검정통계량이 0.25”라는 뜻이 아니다.

---

## 5-2. G*Power 내부 논리: 비중심 모수 $\lambda$ 와 표본 수 $N$

ANOVA에서 검정력을 계산할 때 핵심은 **비중심 F분포** 개념이다.

- 귀무가설이 참일 때: F는 **중심 F분포(central F)** 를 따른다 → 비중심 모수 $\lambda = 0$
- 대립가설이 참일 때: F는 **비중심 F분포(noncentral F)** 를 따른다 → $\lambda > 0$

이때 비중심 모수는

$ \lambda = f^2 \cdot N $

- $f$: 효과크기 (차이의 크기)  
- $N$: 전체 표본 수  
- $\lambda$: “대립가설이 참일 때 F분포가 오른쪽으로 얼마나 이동했는가”를 나타내는 수

$N$이 커지거나, $f$가 커질수록  
→ $\lambda$가 커지고  
→ 대립가설 분포가 오른쪽으로 이동  
→ 같은 임계값에서도 더 자주 그 임계값을 넘는다  
→ **검정력(power)** 이 증가.

G*Power는 이 $\lambda = f^2 N$ 관계를 이용해서  
원하는 검정력(예: 0.8)을 얻기 위한 최소 $N$을 역으로 계산한다.

---

# 📌 6. F분포, 중심 F, 비중심 F

## 6-1. F분포 기본

F분포는 “두 개의 스케일된 카이제곱 분포의 비”로 정의된다.  
항상 $0$ 이상의 값만 가지며, 오른쪽으로 꼬리가 긴 비대칭 분포다.

중심 F분포의 평균은

$ E(F) = \dfrac{df_2}{df_2 - 2} \quad (df_2 > 2) $

- $df_2$가 커질수록 평균은 $1$에 가까워진다.  
  (그래서 “대충 1 근처”라고 느껴지는 것)

---

## 6-2. 중심 F vs 비중심 F

- **중심 F분포**:  
  - 비중심 모수 $\lambda = 0$  
  - “귀무가설이 맞을 때”의 분포  
- **비중심 F분포**:  
  - $\lambda > 0$  
  - “진짜 효과가 있을 때”의 분포  
  - 중심 F분포보다 오른쪽으로 이동한 형태

이 “이동한 정도”가 바로 $\lambda = f^2 N$ 이고,  
이 값이 클수록 대립가설 분포가 오른쪽으로 더 밀려서  
검정력이 올라간다.

---

# 📌 7. 유의수준 $\alpha$, 임계값, 검정력(power)의 기하학

## 7-1. 유의수준 $\alpha$ 와 임계값 $x_\alpha$

1. 우선 **귀무가설 분포**(중심 F)를 기준으로  
   오른쪽 꼬리의 확률이 $\alpha$가 되도록 하는 값을 찾는다.  
   그 점이 **임계값 $x_\alpha$**.

2. 수식으로 쓰면:

- $P(X > x_\alpha \mid H_0) = \alpha$

이게 유의수준의 정의다.

---

## 7-2. 검정력(power)의 정의

이제 **대립가설 분포**(비중심 F)에서 똑같은 임계값 $x_\alpha$을 기준으로  
오른쪽 면적을 구하면, 그게 **검정력**이다.

- $P(X > x_\alpha \mid H_1) = 1 - \beta = \text{power}$

즉,

- $\alpha$: 귀무가설이 맞을 때, 임계값을 넘어서 “잘못 기각”할 확률 (제1종 오류)  
- $\beta$: 대립가설이 맞을 때, 임계값을 넘지 못해서 “못 잡는” 확률 (제2종 오류)  
- $1 - \beta$: 대립가설이 맞을 때, 임계값을 넘어서 “제대로 잡는” 확률 → 검정력

핵심 포인트:

> 유의수준 $\alpha$는 **항상 귀무가설 분포 기준으로 정의**되고,  
> 검정력은 **대립가설 분포가 같은 임계값을 얼마나 자주 넘는가**로 정의된다.

분포가 완전히 같다면(진짜 효과가 없다면)  
→ $P(X > x_\alpha \mid H_0) = P(X > x_\alpha \mid H_1) = \alpha$  
→ power = $\alpha$ 가 되어, 검정은 “진짜 효과를 구분할 힘이 전혀 없는 상태”가 된다.

---

# 📌 8. 통계 검정 vs 머신러닝: α–power vs precision–recall

## 8-1. 대응표

| 통계 | 의미 | 머신러닝 대응 | 의미 |
|------|------|----------------|------|
| 유의수준 $\alpha$ | $H_0$이 맞는데 기각할 확률 | FPR (False Positive Rate) | 실제 음성을 양성으로 |
| 검정력 $1-\beta$ | $H_1$이 맞을 때 기각에 성공할 확률 | Recall (Sensitivity) | 실제 양성을 잡는 비율 |
| 제2종 오류 $\beta$ | $H_1$이 맞는데도 기각 실패 | FNR | 실제 양성을 놓침 |
| 임계값 $x_\alpha$ | 통계량 기준선 | threshold | 분류 기준(예: 0.5 이상 양성) |

---

## 8-2. 트레이드오프 구조

- 통계에서:
  - 임계값을 오른쪽으로 더 엄격하게 두면:
    - $\alpha$ ↓ (제1종 오류 줄어듦)
    - 하지만 $1 - \beta$(power)도 ↓ (진짜 효과를 잡기 어려워짐)

- 머신러닝에서:
  - threshold를 높이면:
    - FPR ↓ (precision ↑)  
    - 하지만 recall ↓ (양성을 많이 놓침)

본질은 같다.

> 두 분포(양성/음성, $H_0/H_1$)가 겹쳐 있기 때문에  
> 하나의 경계선(threshold, 임계값)을 옮길 때  
> False Positive vs False Negative,  
> $\alpha$ vs power, precision vs recall이 서로 엇갈리게 된다.

---

# 📌 9. 핵심 요약

1. **Cronbach’s α = .71**  
   - 문항들이 “같은 개념”을 꽤 일관되게 측정하고 있는 상태  
   - 신뢰도는 양호한 수준  
   - 분산/공분산 구조로 “문항 간 상관”을 수치화한 것  
   - p-value와 직접적인 관련 없음

2. **G*Power, 중간효과크기 .25, $\alpha=0.05$, power=0.8, 집단 수 4, 최소 표본 180명**  
   - 효과크기 $f=0.25$는 “집단 간 차이가 전체 변동의 약 6%를 설명하는 중간 정도”  
   - $\lambda = f^2 N$ 을 통해 비중심 F분포의 이동 정도를 계산  
   - 유의수준과 검정력 조건을 만족하는 최소 $N$을 역으로 계산한 결과가 약 180명  
   - 실제 연구는 학년별 50명, 총 200명, 탈락 고려 220명 → “필요 표본수를 충족했다”

3. **데이터 분석 프로세스에서의 위치**  
   - G*Power, 효과크기, 유의수준, 검정력: 분석 전에 **연구 설계/표본 설계 단계**  
   - Cronbach’s α: 데이터 수집 후 **측정도구 신뢰도 검증 단계**  
   - F값, p값: 나중에 **가설검정 단계**에서 사용

4. **비슷한 문항 여러 개 쓰는 이유**  
   - 단일 문항은 노이즈가 크다 → 같은 개념을 여러 문항으로 측정해 평균/합계를 사용하면 오차가 상쇄  
   - 문항 간 상관이 너무 낮으면: 같은 개념이 아니어서 α↓  
   - 문항 간 상관이 너무 높으면: 중복, α는 높지만 타당도는 떨어질 수 있음  
   → 적당히 상관 있는 문항들을 다양하게 설계하는 것이 베스트

5. **효과크기, F분포, 검정력의 게임**  
   - 효과크기 $f$ 클수록, 표본 수 $N$ 클수록 → $\lambda = f^2 N$ 커져서 대립가설 분포가 오른쪽으로 이동  
   - 유의수준 $\alpha$는 귀무가설 분포에서 정한 임계값 기준,  
   - 검정력은 “대립가설 분포에서 그 임계값을 넘길 확률”  
   - 두 분포가 완전히 같으면 power = $\alpha$ (검정이 무력)  
   - 분포가 확실히 분리될수록 power → 1

6. **머신러닝과의 연결**  
   - 유의수준 ↔ FPR,  
   - 검정력 ↔ recall,  
   - 임계값 ↔ threshold  
   - 둘 다 “겹쳐 있는 두 분포를 한 줄로 나누려고 할 때 생기는 trade-off 문제”라는 점에서 동일한 구조를 가진다.

