# 📌 1. K-means 군집화의 한계와 DBSCAN의 개념

## 1-1. 군집이란 무엇인가

- **군집(Cluster)**: 비슷한 성질을 가진 데이터 포인트들이 모여 있는 집단이다.  
- 군집화(Clustering)는 데이터에 라벨이 없는 상태에서 **비슷한 것끼리 묶어 데이터의 숨겨진 구조를 찾는 과정**이다.
- 예시:  
  - 고객 데이터를 군집화 → 소비 패턴이 비슷한 집단  
  - 환자 데이터를 군집화 → 증상·반응이 유사한 환자 집단  
  - 유전자 데이터를 군집화 → 발현 패턴이 유사한 그룹

---

## 1-2. K-means의 작동 원리와 전제

- K-means는 “**중심점(centroid)에서 가장 가까운 점들끼리 묶는다**”는 거리 기반 알고리즘이다.
- 과정:
  1. K개의 중심을 임의로 지정
  2. 각 점을 가장 가까운 중심에 할당
  3. 각 군집의 평균으로 중심 재계산
  4. 할당이 변하지 않을 때까지 반복
- 전제 조건:
  - 군집이 **구형**에 가깝고
  - **크기와 밀도**가 비슷하며
  - **거리가 기준**이 되어도 경계가 왜곡되지 않는 경우

---

## 1-3. 크기와 밀도가 다르면 문제가 생기는 이유

- 현실 데이터는 다음과 같은 경우가 많다:
  - A 군집: 작고 조밀
  - B 군집: 크고 희박
- 이때 K-means는 거리 기준만 보기 때문에:
  - 희박한 군집의 일부 점을 잘못된 군집에 할당하거나  
  - 중심이 치우쳐 군집 경계가 왜곡된다.
- 즉, **데이터의 실제 구조(자연스러운 그룹)**를 제대로 반영하지 못한다.

✅ 핵심: “정답(라벨)”을 못 찾는다는 말보다 **데이터의 진짜 구조를 파악하지 못한다**고 이해하는 것이 정확하다.

---

## 1-4. DBSCAN의 개념과 K-means와의 차이

- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: 밀도를 기준으로 군집을 찾는 알고리즘
- 핵심 아이디어:
  - 일정 반경(ε) 안에 최소 개수(MinPts) 이상의 점이 있으면 군집의 중심(core)로 간주  
  - 이웃 점들을 계속 연결하여 밀집 영역을 확장  
  - 밀도가 낮은 점은 노이즈로 처리
- 특징 비교:

| 항목 | K-means | DBSCAN |
|------|--------|--------|
| 기준 | 평균까지 거리 | 밀도 |
| 군집 형태 | 구형에 적합 | 임의의 형태도 가능 |
| 크기/밀도 | 비슷해야 잘 작동 | 달라도 잘 작동 |
| 군집 개수 | K를 미리 지정 | 자동 결정 |
| 이상치 | 군집 중 하나에 포함됨 | 노이즈로 분리 가능 |

---

## 1-5. 핵심 요약

- K-means는 **“평균에서 가까운 것끼리 묶기”**라는 단순한 규칙 때문에,  
  **군집 크기나 밀도가 크게 다르면 데이터의 실제 구조를 제대로 찾지 못한다.**
- DBSCAN은 밀도를 기준으로 군집을 찾기 때문에 **군집의 크기·밀도가 달라도 자연스러운 구조를 잘 포착**한다.
- 따라서 데이터 구조가 복잡하거나 이상치가 존재하는 상황에서는 DBSCAN이 더 유용하다.

<br>
<br>
<br>

# 📌 2. 군집분석, 랜덤포레스트 등

---

## 2-1. K-means 군집화의 한계와 개념

**1) 군집(Cluster)의 의미**  
군집이란 유사한 특성을 가진 데이터들의 자연스러운 집합이다. 군집화란 라벨이 없는 상태에서 비슷한 데이터끼리 묶는 비지도 학습(unsupervised learning) 방법이다.

**2) K-means의 한계**  
K-means는 각 점을 "가장 가까운 중심(centroid)"에 할당하며, 각 군집의 평균을 중심으로 업데이트한다.  
하지만 군집의 크기나 밀도가 다르면 문제가 생긴다.

- 큰 군집과 작은 군집이 함께 있을 경우 큰 군집에 끌려 중심이 왜곡된다.
- 밀도가 높은 집단과 희박한 집단이 섞여 있으면 희박한 집단이 잘못 분류된다.

이는 결국 K-means가 **"평균과 거리"만으로 판단하기 때문**이다.

---

## 2-2. 계층적 군집분석

**1) 정의**  
계층적 군집분석은 데이터를 계층적으로 묶어나가며 트리를 만드는 군집 방법이다. K를 미리 정할 필요 없이 덴드로그램(dendrogram)에서 원하는 군집 수를 선택한다.

**2) 주요 연결 방법**  
- **단일 연결법(Single Linkage):** 군집 간 가장 가까운 거리 사용. 이상치에 민감하고 길쭉한 군집 생성 가능.  
- **완전 연결법(Complete Linkage):** 군집 간 가장 먼 거리 사용. 군집이 더 조밀하고 균일해진다.  
- **평균 연결법(Average Linkage):** 두 군집 간 평균 거리를 사용. 단일·완전 연결법의 중간 성질.  
- **와드 연결법(Ward’s Method):** 군집 병합 시 SSE(제곱합) 증가가 최소화되도록 병합. 분산을 최소화하는 가장 안정적인 방법이다.

---

## 2-3. PCA를 이용한 이상치 탐지

주성분 분석(PCA)은 고차원 데이터를 저차원으로 투영해 주요 패턴을 찾는 방법이다. 이상치는 주성분 공간에서 대부분의 데이터가 모여 있는 패턴을 따르지 않는 점을 의미한다.  
즉, PCA를 사용하면 데이터의 주된 변동성에서 벗어나는 관측치를 **이상치(outlier)** 로 식별할 수 있다.

---

## 2-4. Apriori 알고리즘

**1) 정의**  
Apriori는 연관규칙 분석(Association Rule Mining)에서 자주 등장하는 항목집합을 찾는 알고리즘이다.  
예: 장바구니 분석에서 “우유를 산 사람은 빵을 살 확률이 높다” 같은 규칙을 찾는다.

**2) 핵심 아이디어**  
- 자주 등장하는 작은 집합이 자주 등장하는 큰 집합의 부분집합이다.  
- 따라서 작은 집합부터 점차 확장하며 자주 등장하는 집합만 탐색한다.

---

## 2-5. 비정상 시계열의 정상화

비정상 시계열을 정상 시계열로 만드는 목적은 **평균과 분산이 일정한 상태에서 분석**하기 위함이다.  
이를 위해 차분(differencing), 로그 변환(log transform), 계절성 제거 등을 사용한다.

**정규화(normalization)**는 데이터의 스케일을 조정할 뿐, 시간 흐름에 따른 평균·분산의 변화(비정상성)는 제거하지 못하므로 정상화 방법으로 적절하지 않다.

---

## 2-6. 랜덤포레스트와 지니계수

**1) 지니 불순도(Gini Impurity)**  
결정트리에서 노드의 "순도"를 나타내는 지표이다.

- 공식: G = 1 - Σ(pᵢ²)  
- pᵢ: 노드에서 클래스 i의 비율

**2) 해석**  
- G = 0 → 완전히 한 클래스(순수)  
- G ↑ → 여러 클래스가 섞여 있음(불순)

트리는 불순도를 크게 줄이는(split 후 G 감소가 큰) 변수를 선택하여 분할한다.

---

## 2-7. K-means에서 군집 개수(K) 결정과 WCSS

K는 알고리즘이 자동으로 찾지 못하는 하이퍼파라미터이므로 사용자가 직접 정해야 한다.  
이를 위해 **집단 내 제곱합(WCSS)**을 활용한다.

- 공식: WCSS = Σ Σ || xᵢ - μₖ ||²  
- 각 군집 내 데이터가 중심과 얼마나 가까운지 나타낸다.

K를 늘릴수록 WCSS는 감소하지만, 어느 시점부터 감소 폭이 급격히 줄어든다.  
이때의 “팔꿈치(Elbow)” 지점이 최적 K의 후보이다.

---

✅ 요약  
- 군집화: 비슷한 특성을 가진 데이터끼리 묶기  
- K-means: 평균 거리 기반, 크기·밀도 차이에는 취약  
- 계층적 군집: 트리 구조로 군집화  
- PCA: 이상치를 주성분 공간에서 탐지  
- Apriori: 연관 규칙 탐색 알고리즘  
- 비정상 시계열 → 정상화는 차분·로그 등으로  
- 지니계수: 노드 불순도, 분류기준  
- WCSS: 군집 응집력 지표, Elbow 기법으로 K 결정

<br>
<br>
<br>

# 📌 3. 책임원칙 훼손과 동의제 전환의 의미

## 3-1. 책임원칙(Principle of Responsibility)

**책임원칙**이란 사람이 자신의 **행동 결과에 대해서만** 책임을 져야 한다는 원리이다.  
즉, 사람의 성격이나 잠재적 위험성, 생각 같은 **내면적 성향**이 아니라  
**실제로 발생한 행위와 그 결과**에 근거하여 처벌해야 한다는 뜻이다.

| 구분 | 성향 중심 판단 | 행위 중심 판단 |
|------|----------------|----------------|
| 근거 | “그럴 가능성이 있다” | “실제로 했다” |
| 예시 | 폭력적 성향이 있으니 위험하다 | 실제로 폭력을 행사했다 |
| 결과 | 예방적 통제 → 책임원칙 훼손 | 결과 중심 처벌 → 책임원칙 준수 |

따라서 **“책임원칙 훼손”**이란,  
아직 아무런 행위가 없는데도 ‘그럴 가능성이 있다’는 이유로 처벌하거나 감시하는 것이다.

---

## 3-2. 성향에 따른 처벌의 문제점

AI나 데이터 기반 감시체계가  
“범죄 가능성 80%”라고 판단했다고 해서 미리 통제한다면,  
그 사람은 **아직 아무 행동도 하지 않았지만** 불이익을 받게 된다.  

이것은 “결과책임(result responsibility)”이 아니라  
“성향책임(dispositional responsibility)”에 기반한 처벌이므로  
**법철학적으로 부당하다.**

---

## 3-3. 개인정보 보호 체계: 책임제 vs 동의제

| 구분 | 책임제(Responsibility Model) | 동의제(Consent Model) |
|------|------------------------------|------------------------|
| 핵심 개념 | 데이터 수집자가 책임을 지는 구조 | 데이터 주체(개인)가 동의로 통제 |
| 통제 시점 | 사후적 (문제 발생 후 책임 추궁) | 사전적 (정보 제공 전 동의) |
| 초점 | 기업의 관리 의무 | 개인의 자율적 선택 |
| 예시 | 기업이 데이터 보호 정책을 공개 | 사용자가 “수집 동의” 체크 |

즉, **동의제 전환**이란  
데이터 수집자(기업, 정부)가 일방적으로 ‘책임’을 지는 구조에서 벗어나  
**개인이 직접 자신의 정보 제공 여부를 결정**하게 만드는 것이다.

---

## 3-4. 두 개념의 연결

> “책임원칙 훼손”은  
> 사람의 성향을 근거로 사전에 감시하거나 처벌하는 것이고,  
> “동의제 전환”은  
> 이런 감시의 근원이 되는 데이터 수집 자체를  
> 개인이 통제할 수 있도록 바꾸자는 대응책이다.

즉,  
**데이터 기반 예측·감시 → 성향 중심 통제 → 책임원칙 훼손**  
이런 구조를 막기 위해,  
**데이터 제공 단계에서 개인의 ‘사전 동의’를 요구하자**는 것이다.

---

## 3-5. 예시

AI가 SNS, 위치정보, 검색기록을 분석해서  
“폭력 성향 가능성 85%”라고 예측했다고 하자.

- 이걸 근거로 감시하거나 제재하면 → **책임원칙 훼손**  
- 이런 분석이 가능하려면 개인정보 수집이 선행돼야 하므로 →  
  **정보 수집 단계에서 동의제를 적용해야 함**

---

## 3-6. 요약

- **책임원칙 훼손:** 행위가 아닌 ‘성향’으로 처벌하거나 감시하는 것.  
- **동의제 전환:** 사생활 침해를 막기 위해 데이터 수집의 통제권을 개인에게 돌리는 것.  
- 결론적으로, 동의제 전환은 책임원칙을 지키기 위한 정보윤리적 대안이다.

---
