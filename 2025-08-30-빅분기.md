# 📌 1. 가설검정 vs 모델링

| 구분         | **가설검정 (Hypothesis Test)** | **모델링 (Modeling)**      |
| ---------- | -------------------------- | ----------------------- |
| **목적**     | 관계의 **존재 유무 확인** (있다/없다)   | 관계의 **크기·방향·형태 수식화**    |
| **출력 결과**  | P-value, 기각 여부 (Yes/No)    | 회귀계수, 예측식, 적합도(R²) 등    |
| **데이터 구조** | 주어진 변수들로 검정통계량 계산          | 독립변수(X)와 종속변수(Y) 관계 정의  |
| **예시 질문**  | “남녀 평균 키 차이가 있는가?”         | “성별이 키에 몇 cm 영향을 주는가?”  |
| **대표 방법**  | Z-검정, t-검정, χ² 검정, ANOVA   | 회귀분석, 로지스틱 회귀, 의사결정나무 등 |
| **해석 수준**  | **있다 / 없다** (통계적 유의성)      | **얼마나? 어떻게?** (크기, 예측력) |
| **위치**     | 분석 과정의 **탐색/검증 단계**        | 분석 과정의 **모델 구축 단계**     |


# 📌 2. 가설검정에 대하여
| 상황               | 비교 기준 (독립변수) | 비교 대상 (종속변수) | 귀무가설(H₀)                   | 대표 검정법                          | 검정통계량                                 |
| ---------------- | ------------ | ------------ | -------------------------- | ------------------------------- | ------------------------------------- |
| **1표본 평균 검정**    | 상수(기준값)      | 연속형 평균       | $\mu = \mu_0$              | **1표본 Z/t-검정**                  | $\frac{\bar{X} - \mu_0}{SE}$          |
| **2표본 평균 검정**    | 범주형(2집단)     | 연속형 평균       | $\mu_1 = \mu_2$            | **독립표본 t-검정**, Z-검정(σ² 알고 있을 때) | $\frac{\bar{X}_1 - \bar{X}_2}{SE}$    |
| **3집단 이상 평균 검정** | 범주형(3집단 이상)  | 연속형 평균       | $\mu_1 = \mu_2 = \mu_3...$ | **ANOVA(F-검정)**                 | $F = \frac{MSB}{MSW}$                 |
| **범주 vs 범주**     | 범주형          | 범주형          | 변수들은 독립이다                  | **χ²(카이제곱) 검정**                 | $\chi^2 = \sum \frac{(O-E)^2}{E}$     |
| **연속 vs 연속**     | 연속형          | 연속형          | 두 변수는 상관이 없다               | **상관분석 (Pearson r)**            | $r = \frac{\text{공분산}(X,Y)}{s_X s_Y}$ |

1. 가설검정의 사고 실험

귀무가설(H₀)이 참인 세계를 먼저 가정한다.

예: “남녀 평균 키는 같다”, “모평균은 100이다”, “두 변수는 독립이다”.

그 가정하에서 모집단에서 표본을 무한히 뽑는다고 상상한다.

매번 뽑을 때마다 표본평균, 분산, 빈도 등 통계량이 계산된다.

그때마다 검정통계량을 계산한다.

(평균 차이 / 표준오차), (제곱합 / 기대값), (분산 비율) … 등

검정 목적(평균 차이? 독립성? 분산 비교?)에 따라 공식이 달라짐.

이렇게 얻은 검정통계량들을 전부 쌓아보면, 이론적으로 **특정 분포(Z, t, F, χ²)**를 따른다.

2. 실제 검정 절차

나는 지금 표본을 딱 1번 뽑아 실제 검정통계량을 계산한다.

그 값을 아까 말한 귀무가설 하 분포 위에 올려본다.

분포 중앙(신뢰구간)에 있으면 → “우연한 차이일 수도 있네 → H₀ 기각 못함”

분포 꼬리(기각역)에 있으면 → “이런 값이 나올 확률 너무 작네 → H₀ 기각”

3. 핵심 포인트

검정통계량은 고정된 게 아니다.
→ “내가 무엇을 비교하고 싶은지(평균? 분산? 범주 간 독립성?)”에 따라 정의가 달라진다.

분포 모양도 달라진다.
→ 평균을 표준화하면 Z/t, 분산비율이면 F, 제곱합이면 χ².

신뢰구간과 기각역은 결국 같은 기준선
→ 신뢰구간 밖 = 기각역, 안 = 채택역.

# 📌 3. 교차분석과 교차 검증
1. 교차분석 (Cross-tab Analysis)

정의: 두 범주형 변수 간의 관계를 보는 기초 통계 분석 기법. (교차표, 분할표 사용)

예시: “성별(남/여)과 구매여부(구매/미구매)는 관련이 있는가?”

도구: 카이제곱 검정(χ² test) 같이 범주형 관계의 유의성을 확인.

👉 빅데이터 분석 단계에서의 위치

EDA(Exploratory Data Analysis, 탐색적 데이터 분석) 단계

즉, 데이터를 이해하고 특징을 파악하는 과정에서 사용됨.

모델링 이전에, 변수들 간 기본적인 상관이나 패턴을 찾는 데 쓰인다.

2. 교차검증 (k-fold Cross Validation)

정의: 데이터를 k개의 조각(fold)으로 나눠서, 한 조각은 검증용, 나머지는 학습용으로 사용해 모델을 반복적으로 학습·검증하는 기법.

목적: 모델이 특정 데이터에만 잘 맞는 **과적합(overfitting)**을 막고, 일반화 성능을 확인하기 위함.

예시: 데이터를 5등분 → 4개로 학습, 1개로 검증 → 이 과정을 5번 반복 → 평균 정확도로 모델 평가.

👉 빅데이터 분석 단계에서의 위치

모델링 및 검증 단계

즉, 머신러닝 모델을 만들고, 그것이 잘 작동하는지 평가하는 과정에서 사용됨.

3. 직관적으로 요약

교차분석: “변수 A와 B가 관련 있나?” → 데이터 탐색(EDA)에서 사용.

교차검증: “내 모델이 잘 작동하나?” → 모델링 성능 검증에서 사용.

# 📌 4. 피쳐의 의미
1. 기본 정의

피처(feature) = 데이터의 속성, 즉 신경망이 학습에 사용하는 입력 변수.
예: 학생 성적 예측 → 공부시간, 수면시간, 아침식사 여부 등이 피처.

피처 개수를 추가한다 = 입력으로 사용하는 변수를 더 넣는다.
즉, 신경망의 입력층(input layer) 노드(뉴런) 개수가 늘어난다는 뜻.

# 📌 5. pca에서 svd랑 공분산 행렬의 선택
## 1. 현실에서 보통 \( n \gg p \)

예: 학생 1,000명에게서 과목 점수 5개를 조사  
- \( n = 1000 \)  
- \( p = 5 \)  

데이터 행렬 \( X \): \( 1000 \times 5 \)  

👉 행(표본)이 훨씬 많고, 열(변수)은 상대적으로 적다.  
👉 이 경우 PCA는 문제없이 공분산 행렬 \( 5 \times 5 \) 만들어서 분해하면 된다.  

---

## 2. 하지만 \( p \gg n \) 인 경우도 있다

유전자 분석, 이미지 처리 같은 분야:  
- 표본은 몇 백 개밖에 없는데, 변수는 수만 개 (픽셀, 유전자 자리수 등)  

예:  
- \( n = 100 \)  
- \( p = 10,000 \)  

👉 이때는 공분산 행렬이 \( p \times p = 10,000 \times 10,000 \) 이라서 직접 계산하기 힘들다.  
👉 그래서 이런 상황에서는 **SVD를 사용해서 \( n \times p \) 데이터 행렬 자체를 분해**하는 방식이 훨씬 효율적이다.  

---

## 3. 핵심 정리

- 보통 경우: \( n \gg p \) → 그냥 공분산 행렬 \( p \times p \) 만들어서 PCA 하면 됨.  
- 특수 경우(고차원 데이터): \( p \gg n \) → **SVD 방식으로 PCA** 해야 효율적.  

결국 둘 다 **같은 결과(주성분 축과 설명력)**을 준다.