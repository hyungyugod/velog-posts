# 📌 1. 알고리즘 접근권(Algorithmic Access Rights)
## 1-1. 정의
- 개인/집단이 자신에게 영향을 미치는 알고리즘에 대해 **접근(정보 열람)**, **이해(설명 가능성)**, **감시/이의제기**를 할 수 있는 권리.
## 1-2. 핵심 포인트
- **투명성**과 **설명가능성**의 실무적 구현이 관건(소스코드 전면 공개 의미 아님).
- 의료·공공 영역에선 편향·차별 검증을 위한 최소한의 구조적 접근이 필요.

---

<br>
<br>
<br>

# 📌 2. 군집분석: 계층적 vs 분할적 vs 비계층적
## 2-1. 계층적(Hierarchical)
- 응집적(아래→위) 또는 분할적(위→아래) 방식으로 **덴드로그램** 생성, 절단 높이로 군집 수 결정(사전 $k$ 불필요).
## 2-2. 분할적(Divisive)
- 전체 집단에서 시작해 큰 이질 그룹부터 **분기**, 절단 기준이나 목표 $k$에서 정지.
## 2-3. 비계층적(Partitional)
- **처음부터 $k$를 정해** 반복 최적화. 예: K-means, K-medoids, GMM.

---

<br>
<br>
<br>

# 📌 3. “분할적 군집은 특정 수로 나눈다”의 해석
## 3-1. 정확한 의미
- 트리를 쪼개 **가다가** 원하는 $k$ 또는 임계값에서 **멈춘 결과**가 $k$개일 뿐, K-means처럼 **초기에 $k$를 강제 입력**하는 것과 다름.

---

<br>
<br>
<br>

# 📌 4. ACF와 PACF: 정의(식 기준)
## 4-1. ACF(자기상관함수)
- $ \rho_k=\dfrac{\sum_{t=k+1}^{T}(x_t-\bar x)(x_{t-k}-\bar x)}{\sum_{t=1}^{T}(x_t-\bar x)^2} $  
- 두 시점 $(t,\,t-k)$의 **총상관(직접+간접)**.
## 4-2. PACF(부분자기상관함수)
- $x_t$와 $x_{t-k}$를 **중간 시차들을 회귀로 제거한 잔차**끼리의 상관. “직접 연결”만 본다.

---

# 📌 5. AR/MA/ARMA/ARIMA에서 ACF·PACF 패턴
## 5-1. 모형식
- AR($p$): $X_t=\sum_{i=1}^{p}\phi_i X_{t-i}+\varepsilon_t$
- MA($q$): $X_t=\varepsilon_t+\sum_{i=1}^{q}\theta_i\varepsilon_{t-i}$
- ARMA($p,q$): AR과 MA 결합
- ARIMA($p,d,q$): $(1-B)^d X_t$가 ARMA($p,q$)
## 5-2. 패턴 요약
- **AR($p$)**: ACF **감쇠**, PACF **$p$에서 cut-off**  
- **MA($q$)**: ACF **$q$에서 cut-off**, PACF **감쇠**  
- **ARMA($p,q$)**: 둘 다 **감쇠(뚝 끊김 없음)**  
- **ARIMA($p,d,q$)**: **차분 전** ACF 느린 감쇠(추세·단위근 영향), **차분 후** ARMA 패턴.

---

<br>
<br>
<br>

# 📌 6. 직관 핵심(왜 그런가)
## 6-1. AR은 “연쇄(도미노)”
- 과거 $X$가 현재를 만들며 영향이 **간접 경로로 무한 전파** → ACF는 꼬리, PACF는 **직접항 개수($p$)** 이후 0.
## 6-2. MA는 “공유된 오차창(유한기억)”
- $X_t$가 **유한 개수의 오차**만 섞음 → 특정 lag 이후 **공통 오차 부재** → ACF cut-off.  
- 그러나 “AR($\infty$) 전개” 관점에서 **직접효과가 무한히 작게 남아** PACF는 감쇠 꼬리.

---

<br>
<br>
<br>

# 📌 7. 그래프 관찰 결론(시뮬레이션)
## 7-1. AR(2)
- ACF: 점진 감쇠, PACF: **lag=2**에서 급락(cut-off).
## 7-2. MA(1)
- ACF: **lag=1** 이후 0, PACF: 점진 감쇠(잔향).

---

<br>
<br>
<br>

# 📌 8. R `sleep` 데이터 문항 판별
## 8-1. 요약값 핵심
- 평균(mean) ≈ 1.54, 중앙값(median) ≈ 0.95, 최대 5.5.
## 8-2. 보기 판단
- “평균 0.95증가”는 **중앙값을 평균으로 오해** → 틀림.  
- “0.9이상 증가가 50% 초과”도 **중앙값 해석 오류** → 틀림.  
- 최대 5.5는 참, 그룹 간 평균차는 ≈ 1.58.  
- 결과적으로 **복수 오답 가능**하여 출제 논리 모호.

---

<br>
<br>
<br>

# 📌 9. 라쏘·릿지·엘라스틱넷
## 9-1. 페널티와 효과
- **Lasso**: $L_1$ 패널티($\sum|{\beta}|$) → **희소성** 유도, 계수 **정확히 0** 가능(변수 선택).  
- **Ridge**: $L_2$ 패널티($\sum \beta^2$) → 계수 축소(0은 잘 안 됨).  
- **Elastic Net**: $L_1+L_2$ 혼합(선택성과 안정성 절충).
## 9-2. 결론
- “라쏘가 **L2**로 0 만든다”는 진술은 **오류**. 올바른 건 **L1**.

---

<br>
<br>
<br>

# 📌 10. VIF(분산팽창계수)와 기울기 의미
## 10-1. VIF 정의와 해석
- $VIF_i=\dfrac{1}{1-R_i^2}$, 여기서 $R_i^2$는 $X_i$를 나머지 $X$로 회귀한 결정계수.  
- **$VIF \to 1$**: 공선성 거의 없음 → **계수 추정 안정**.  
- **$VIF$ 큼**: 공선성 큼 → **계수 분산↑, 신뢰구간 넓어짐**.
## 10-2. “기울기” 의미
- 회귀계수 $\beta_j$는 **$X_j$가 1 증가할 때 $Y$의 평균 변화량**.  
- VIF는 **기울기의 크기**가 아니라 **그 추정의 불안정성(분산)** 을 의미.

---

<br>
<br>
<br>

# 📌 11. 쿡의 거리(Cook’s Distance)
## 11-1. 정의와 식
- 한 관측치를 제거했을 때 **전반적 적합의 변화(영향력)**.  
- 전형적 형태: $D_i=\dfrac{e_i^2}{p\cdot MSE}\cdot\dfrac{h_{ii}}{(1-h_{ii})^2}$  
  (잔차 $e_i$, 레버리지 $h_{ii}$, 모수 수 $p$)
## 11-2. 해석
- **잔차 큼 + 레버리지 큼** → $D_i$ 큼(영향점).  
- 경험적 기준: $D_i>1$ 또는 $D_i>\frac{4}{n}$이면 영향 큼으로 의심.

---

