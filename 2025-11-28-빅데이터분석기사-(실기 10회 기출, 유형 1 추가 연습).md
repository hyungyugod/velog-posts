# 📌 1. 10회 기출
## 1-1. 1유형
- 문제에서 아예 안쓰이는 칼럼은 아예 삭제하고 하는게 보기에 편한 것 같다.
- 각 text를 단어 수로 변경하기
- 나는 함수를 만들어서 apply를 통해 계산했는데 str로 연산 두번 하는것도 가능하고 띄어쓰기 개수 + 1도 가능하다.
- 그리고 series 니까 rest_index안하고 바로 인덱스 이름으로 접근하면 좀 편리한건 있다.
```py
# 1. 각 메시지의 단어 개수 구하기 (띄어쓰기 기준)
df["단어"] = df["text"].str.split()
df["단어수"] = df["단어"].str.len()
df.head()

# 2. 스팸과 정상 메시지의 평균 단어 수 구하기
m = df.groupby("label")["단어수"].mean()

# 3. 두 평균 차이의 절댓값 구하기
diff = abs(m["spam"] - m["ham"])
```
- 혹은 아래처럼
```py
# 1. 각 메시지의 단어 개수 구하기 (띄어쓰기 기준)
df["단어수"] = df["text"].str.count(" ") + 1
```
- 아래 코드가 중요한데 월까지만 뽑고 싶을때 아래처럼 지정해주면된다.
```py
df["year_month"] = df["order_date"].dt.to_period("M")
```
- 분기로 묶을때는 아래처럼 쓸 수 있다.

| order_date | to_period("Q") 결과 |
| ---------- | ----------------- |
| 2024-01-15 | 2024Q1            |
| 2024-02-28 | 2024Q1            |
| 2024-03-30 | 2024Q1            |
| 2024-04-10 | 2024Q2            |
| 2024-10-01 | 2024Q4            |

- 마지막 제출형식 반올림 등을 꼭 여러번 봐서 확인하고 제출해야한다.
- 데이터프레임끼리 연산해서 새 데이터프레임 만들기
```py
df = df[['sub_topic', 'is_correct']]
total_c = df.groupby('sub_topic')['is_correct'].count()
total_s = df.groupby('sub_topic')['is_correct'].sum()
total_acc = total_s / total_c
print(round(total_acc.sort_values(ascending=False),3)) # 0.673913
```

## 1-2. 2유형
- max_depth=12, n_estimators=2100, learning_rate=0.2 이렇게되면 뭔가 이상하다. 이런 경우에는 모델이 과적합될 수 있기 때문에 crossvalidation이나 train과 비교해볼 수 있다.
```py
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, train, target, cv=5, scoring="neg_root_mean_squared_error")
print(-scores.mean(), -scores.std())
```
- 아니면 이런식으로 train데이터와 함께 검사하여 과적합 가능성을 줄인다.
- 그런데 보통 이 차이가 200정도는 나는거 같아서 한 100 언저리면 그냥 안심을 해도 될 것 같다.
```py
pred_train = model.predict(x_tr)
pred_val = model.predict(x_val)

print("train RMSE:", root_mean_squared_error(y_tr, pred_train))
print("val RMSE:", root_mean_squared_error(y_val, pred_val))
```

| val - train 차이 | 해석                    |
| -------------- | --------------------- |
| 0~5%           | 안정적, 과적합 거의 없음        |
| 5~15%          | 경계선 — 모델 복잡도 조정 가치 있음 |
| 15% 이상         | 과적합 가능성 높음          |
| 극단적으로 큼        | train을 거의 외웠을 가능성    |

- 그리고 결측치가 있으면 결측치를 여러방면으로 처리해보고 결과가 가장 좋은것으로 진행하는 것이 좋다.

## 1-3. 3유형
- params 랑 pvalue헷갈리지 말기 오즈비 구할때는 params이다.
```py
import numpy as np
print(round(np.exp(model.params['age']),3)) # 1.255
```
- 또 다시 적합할때 새로운 변수를 만들었으면 새로운 formula와 새로운 모델을 사용해주어야한다.
- new_formula가 아니라 formula여서 틀렸었다.
```py
new_formula = 'heating_load ~ roof + glazing + height'
new_model = ols(new_formula, data=df).fit()
print(round(new_model.rsquared,3)) # 0.754
```
- 그리고 new_pred는 시리즈(Series) 라서 보통은 new_pred[0]처럼 꺼내서 쓰는 게 깔끔하다.
```py
new_data = pd.DataFrame({
    'wall' : [20],
    'roof' : [150],
    'glazing' : [20],
    'height' : [5]
})

new_pred = new_model.predict(new_data)
print(round(new_pred,3)) # 79.442
```

# 📌 2. 유형 1 연습문제
## 2-1. dayofweek

| 숫자    | 요일              |
| ----- | --------------- |
| **0** | 월요일 (Monday)    |
| **1** | 화요일 (Tuesday)   |
| **2** | 수요일 (Wednesday) |
| **3** | 목요일 (Thursday)  |
| **4** | 금요일 (Friday)    |
| **5** | 토요일 (Saturday)  |
| **6** | 일요일 (Sunday)    |

- 만약 df = df['주문시간']의 결과가 한 열이라면 이는 series가 되므로 원활하게 다음 일을 진행하기 위해선 df = df[['주문시간']] 이런식으로 해서 대입해주어야한다.
```py
df['주문시간'] = pd.to_datetime(df['주문시간']).dt.dayofweek
df = df[['주문시간']]

cond = (df['주문시간'] == 5) | (df['주문시간'] == 6)

print(abs(len(df[cond]) - len(df[~cond])))
```

## 2-2. pivot table 주의할 점
- 첫 번째 코드
- values='건수', columns='구분' → 단일 컬럼 인덱스
- pivot_df['검거건수'] 바로 가능
- 두 번째 코드
- values=['건수'], columns=['구분'] → MultiIndex 컬럼(2단계)
- df['검거건수'] 는 없고 df[('건수','검거건수')] 만 존재
- 하나만 넣을때는 왠만하면 그냥 주자
-  또한 groupby는 새로운 인덱스를 만드는 게 아니다.