# 📌 1. 독립변수 증가와 결정계수(R²)

## 1-1. R²의 정의
- 결정계수는 회귀모형이 종속변수의 변동을 얼마나 설명하는지를 나타내는 지표이다.
- 기본식:  
  $R^2 = \dfrac{SSR}{SST} = 1 - \dfrac{SSE}{SST}$
  - $SST$: 전체제곱합(Total Sum of Squares) — 종속변수의 전체 변동
  - $SSR$: 회귀제곱합(Regression Sum of Squares) — 모형이 설명한 변동
  - $SSE$: 오차제곱합(Error Sum of Squares) — 모형이 설명하지 못한 변동

## 1-2. 왜 독립변수가 늘면 R²는 절대 줄지 않는가
- 회귀계수는 최소제곱법(OLS)으로 추정되며, 이는 $SSE$를 최소화하는 해를 찾는다.
- 새로운 독립변수를 추가하면 모형이 표현할 수 있는 자유도가 커지므로:
  - $SSE$는 **줄거나 그대로**이고
  - 따라서 $1 - \dfrac{SSE}{SST}$ 인 $R^2$는 **늘어나거나 그대로**이다.
- 즉, $R^2$는 독립변수 추가 시 **단조비감소(monotonically non-decreasing)** 한다.

## 1-3. 이것이 곧 “좋은 모델”을 의미하지는 않는다
- 변수만 마구 넣어도 $R^2$는 오른다 → 과적합(overfitting) 위험
- 그래서 **보정된 결정계수(Adjusted $R^2$)** 를 쓴다.
  - 대략형식:  
    $\text{Adj }R^2 = 1 - \dfrac{SSE/(n-k-1)}{SST/(n-1)}$
  - 불필요한 변수를 넣으면 분모·분자의 자유도 때문에 값이 **줄어들 수** 있다.

---

# 📌 2. MDS(다차원 척도법)의 기본 개념

## 2-1. MDS가 하는 일
- MDS(Multidimensional Scaling)는 “객체들 사이의 유사성/비유사성” 정보를 받아서
- 그것을 2차원이나 3차원 좌표 위에 **점(point)** 으로 배치하는 방법이다.
- 목표: “비슷한 건 가깝게, 다른 건 멀게” 시각화.

## 2-2. 입력과 출력
- **입력:** 개체 간 거리행렬(또는 비유사도 행렬)  
  예: A-B는 3, A-C는 5, B-C는 2 …
- **출력:** 각 개체의 좌표 $(x_i, y_i)$ 또는 $(x_i, y_i, z_i)$
- 좌표 간 실제 유클리드 거리 $d_{ij}$가 입력 거리 $\delta_{ij}$와 최대한 비슷해지도록 한다.

## 2-3. 왜 쓰는가
- 원래 변수 차원이 크거나 변수 의미가 불명확할 때,
- 사람의 “심리적 거리”를 표현하고 싶을 때(브랜드, 이미지, 음악 선호도 등),
- PCA처럼 차원축이 명시적 의미를 갖지 않아도 **관계 구조**만 보이고 싶을 때 쓴다.

---

# 📌 3. 계량적 MDS vs 비계량적 MDS

## 3-1. 계량적(Metric) MDS
- 입력 거리의 **수치적 크기** 자체를 보존하려는 MDS
- 목표식(예시):  
  $Stress = \sqrt{\dfrac{\sum (d_{ij} - \delta_{ij})^2}{\sum \delta_{ij}^2}}$
  - $\delta_{ij}$: 주어진(관측된) 거리
  - $d_{ij}$: 좌표로부터 계산한 거리
- 즉 “관측된 거리가 10이면 좌표에서도 10 근처가 되게” 만들고 싶어함.
- 물리적 거리, 시간, 가격처럼 절대값 자체가 의미 있는 데이터에 적합.

## 3-2. 비계량적(Non-metric) MDS
- 입력 거리의 **서열(order, rank)** 만 맞으면 된다.
- 즉 “A-B가 A-C보다 가깝다”는 순서관계만 보존하고,
- 거리의 실제 크기는 단조증가 함수 $f(\cdot)$ 를 통해 변형해도 된다.
- 대표식:  
  $Stress = \sqrt{\dfrac{\sum (d_{ij} - f(\delta_{ij}))^2}{\sum d_{ij}^2}}$
  - 여기서 $f(\cdot)$ 는 단조증가만 하면 된다.
- 심리학, 설문, 감성평가 같이 **사람이 준 점수**처럼 비선형적이고 서열적인 데이터에 적합.

## 3-3. 차이 요약
- 계량적: “거리가 2배면 실제로도 2배 멀어야 해”
- 비계량적: “누가 더 가깝냐만 중요해. 정확한 배율은 안 중요해”

---

# 📌 4. 실루엣 계수(Silhouette Coefficient)

## 4-1. 목적
- 군집분석에서 “현재 이 데이터 포인트가 잘 묶여 있는가?”를 평가하는 지표.
- 한 점 단위로 계산해서 군집의 응집도(cohesion)와 분리도(separation)를 동시에 본다.

## 4-2. 구성요소
한 관측치 $i$ 에 대해 두 값을 계산한다.

1. **군집 내 평균거리**  
   $a(i)$: 관측치 $i$와 **같은 군집**에 속한 다른 관측치들과의 평균거리  
   → 작을수록 좋다. (내 집단 안에서 잘 뭉쳐 있음)

2. **가장 가까운 다른 군집과의 평균거리**  
   $b(i)$: 관측치 $i$가 속하지 않은 **다른 군집들** 각각과의 평균거리를 계산해서  
   그중 **가장 작은 것**을 택한 값  
   → 클수록 좋다. (다른 군집과는 떨어져 있음)

## 4-3. 실루엣 계수 식
- 한 관측치의 실루엣 계수:
  $$
  s(i) = \dfrac{b(i) - a(i)}{\max(a(i), b(i))}
  $$
- 범위: $-1 \le s(i) \le 1$
  - $s(i) \approx 1$: 제 군집에 잘 들어가 있음
  - $s(i) \approx 0$: 군집 경계에 있음
  - $s(i) < 0$: 다른 군집이 더 가깝다 → 잘못 군집됐을 가능성

## 4-4. 해석 구조 뜯어보기
- $a(i)$: “내 편과의 친밀도”
- $b(i)$: “다른 편 중 가장 헷갈리는 편과의 거리”
- $(b(i) - a(i))$: “내 편이 다른 편보다 얼마나 더 가까운가”
- $\max(a(i), b(i))$로 나누는 이유: 값의 크기를 $[-1, 1]$로 정규화해서 비교 가능하게 하려는 것.

## 4-5. 전체 군집 평가
- 전체 데이터의 $s(i)$ 평균을 내면 군집모형 전체의 품질을 알 수 있다.
- 이 평균 실루엣을 군집 수 $k$ 를 바꿔가며 비교 → 적정 군집 수 선택에 활용.

---

# 📌 5. 합동 분산(Pooled Variance)

## 5-1. 정의
- 두 집단이 **같은 모분산**을 가진다고 가정할 때,
- 각 표본 분산을 하나로 묶어서 공통된 분산을 추정한 값.
- 등분산을 가정한 **독립표본 t-검정**에서 자주 쓴다.

## 5-2. 식
- 합동분산:
  $$
  s_p^2 = \dfrac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}
  $$
  - $s_p^2$: 합동분산
  - $s_1^2, s_2^2$: 각 집단의 표본분산
  - $n_1, n_2$: 각 집단의 표본수
  - 분모 $n_1 + n_2 - 2$ 는 두 집단의 자유도 합이다.

## 5-3. 왜 이렇게 생겼나
- 단순 평균이 아니라 **가중평균**을 쓰는 이유:
  - 표본 수가 큰 집단의 분산이 더 신뢰할 만하므로 그 집단에 더 큰 가중을 준다.
- “두 집단이 진짜로 같은 분산을 가진다”는 전제 아래,
  - 각각의 분산 추정보다 둘을 합쳐서 추정하는 편이 더 효율적이다.

## 5-4. t-검정에서의 활용(맥락만)
- 표본평균 차이를 검정할 때 표준오차는
  $$
  SE = \sqrt{s_p^2 \left( \dfrac{1}{n_1} + \dfrac{1}{n_2} \right)}
  $$
  으로 계산해서 t-통계량을 만든다.

---

# 📌 6. 서로의 관계 한 번에 보기

## 6-1. 공통 철학
- $R^2$ → “설명력”  
- MDS → “거리구조를 보존하는 시각화”  
- 실루엣 → “군집이 진짜로 모여 있는지, 다른 군집과 떨어졌는지”  
- 합동분산 → “두 집단을 하나의 분산으로 본다”  
→ 다들 결국 “데이터의 구조를 더 정확하고 공정하게 보겠다”는 같은 철학을 가진다.

## 6-2. 참고할 만한 출처
- Borg, I. & Groenen, P. “Modern Multidimensional Scaling”
- Kaufman & Rousseeuw, “Finding Groups in Data” (실루엣 계수 원전)
- 통계학 개론서(두 집단 평균 비교 장) — 합동분산 부분
- 위키피디어(“Multidimensional scaling”, “Silhouette (clustering)”, “Pooled variance”)

