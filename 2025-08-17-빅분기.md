# 📌 0. 빅데이터 탐색 - 데이터 전처리 
### 📌 0-1. 데이터 정제
1. 변수와 관측값

변수(Variable) : 단위(Unit)의 특성(속성)을 수치나 범주로 표현한 것 (예: 키, 몸무게, 혈액형).

관측값(Observation) : 각 단위에서 실제로 기록된 정보 (예: A학생의 키 170cm, 몸무게 65kg).

값(Value) : 변수에서 관찰된 실제 수치 (170, 65 등).

2. 단변량 자료

정의 : 특성변수가 하나인 자료.

예시 : 학생들의 수학 점수만 모은 데이터.

비교 :

단변량 → 변수 1개

이변량 → 변수 2개

다변량 → 변수 3개 이상

3. 정성적 vs 정량적

정성적(定性的, Qualitative) : 수치로 측정하기보다는 성질·특징으로 구분 (예: 성별, 혈액형, 고객 불만 내용).

정량적(定量的, Quantitative) : 수치로 측정 가능 (예: 키, 몸무게, 매출액).

4. 종적 vs 횡적 자료

종적(縱的, Longitudinal) : 같은 대상을 시간의 흐름에 따라 반복 관찰 (예: 학생 100명의 5년간 체중 변화).

횡적(橫的, Cross-sectional) : 한 시점에서 여러 대상을 단면적으로 조사 (예: 2025년 고등학생 평균 키).

5. 비정형 데이터 변환의 필요성

비정형 데이터(텍스트, 이미지, 로그 등)는 그대로는 분석 불가.

통계·머신러닝 기법은 정형 데이터(숫자·범주)를 입력으로 요구.

따라서 정형 데이터로 변환(전처리) 과정이 필수.

6. 유의수준 (Significance Level, α)

가설검정에서 귀무가설이 참인데도 잘못 기각할 확률(제1종 오류 허용치).

보통 0.05, 0.01, 0.10 사용.

해석: “우연히 나타날 수 있는 확률이 α 이하라면, 결과를 유의하다고 판단.”

7. 결측치(Missing) 유형

MCAR : 완전 무작위 결측 (아무 변수와도 무관).

MAR : 무작위 결측 → 다른 변수와는 관련 있지만, 결측값 자체(비관측값)와는 무관.

MNAR : 비무작위 결측 → 결측 여부가 실제 값 자체와 관련.
👉 “무작위(MAR)”라 부르는 이유 = 결측 여부가 다른 변수와는 관련 있지만, 빠진 값 자체와는 무작위처럼 보이기 때문.

8. 회귀분석과 회귀모형

회귀분석 : 독립변수(X)가 종속변수(Y)에 미치는 영향을 수학적으로 모형화하는 기법.

회귀모형 : X와 Y의 관계를 단순화해 가정한 구조 

모형은 현실을 100% 설명하는 식이 아니라, 현상을 단순화한 가설적 틀.

9. 회귀 대치법 (조건부 평균 대치법)

단순 평균 대치: 모든 결측을 전체 평균으로 대체 → 변동성 왜곡.

회귀 대치법: 다른 변수(X)로 회귀식을 만들어 조건부 기대값으로 대체.

예: 
𝑌=50+5𝑋 Y=50+5X, X=10일 때 결측 Y=100으로 대체.

그래서 조건부 평균 대치법이라 부름.

10. 이상치(Outlier)

문제점 : 평균·분산·표준편차에 큰 영향, 하지만 중앙값·사분위수에는 영향 적음.

이유: 평균·분산은 모든 값을 직접 반영, 중앙값은 순서만 반영 → 극단값 영향 작음.

11. 정상성(Normality)

데이터가 정규분포(Normal Distribution)를 따르는 성질.

많은 통계 기법은 정상성을 가정.

정상성 감소 = 데이터가 점점 정규분포 모양에서 벗어남(왜도·첨도 증가, 이상치 존재 등).

12. 모수적 vs 비모수적

모수(母數, Parameter) = 모집단을 대표하는 기본 수치(μ, σ 등).

모수적(Parametric) : 모수와 분포 가정을 전제로 하는 방법 (t-검정, ANOVA, 회귀분석).

비모수적(Non-parametric) : 분포 가정 없이 순위·빈도로 분석 (카이제곱, Wilcoxon, Mann-Whitney U).

영어 어원:

parameter = para(곁) + meter(측정) → 어떤 시스템을 규정하는 값

parametric = parameter에 의존하는

non-parametric = parameter에 의존하지 않는

13. Z-스코어를 이용한 이상치 탐지
$z_i = \frac{x_i - \mu}{\sigma}$
$$
|z_i| > z_{thr} \quad \Rightarrow \quad \text{이상치} \quad (z_{thr}=2 \text{ 또는 } 3)
$$
해석: 데이터가 평균에서 임계 표준편차 이상 벗어나면 이상치로 판정.

14.  평균과 표준편차 기호 유래

평균(μ) : mean → m → 그리스 문자 μ (모집단 평균).

표준편차(σ) : standard deviation → s → 그리스 문자 σ (모집단 표준편차).

통계에서는 모집단 parameter를 그리스 문자(μ, σ, π 등)로 표기.

15. 고립의사나무 (Isolation Forest)

이상치 탐지 알고리즘.

아이디어: 이상치는 다른 점들과 멀리 떨어져 있으므로, 랜덤 분할 트리에서 짧은 경로로 고립됨.

정상치는 데이터 뭉치 속에 있어 여러 번 분할해야 고립됨.

“나무(Tree)”라 부르는 이유 = 데이터 분할이 의사결정나무 구조(뿌리→가지→잎)로 표현되기 때문.

### 📌 0-2. 분석 변수 처리
1. 변수 선택(Variable Selection)

전진 선택법(Forward Selection)

모든 독립변수 중 종속변수와 단순상관계수(절댓값)가 가장 큰 변수를 먼저 포함.

이후 유의성 검증(부분 F 검정)을 통해 다른 변수를 단계적으로 추가.

→ “가중치(회귀계수)가 큰 변수”라기보다는 “종속변수와 직접 상관이 큰 변수”를 선택하는 것.

부분 F 검정

"추가된 변수(설명력)가 통계적으로 의미 있나?"를 검증.

부분: 추가된 특정 변수만 따로 본다는 뜻.

F 검정: 전체 분산 대비 그룹 간 분산을 비교하는 통계적 검정.

2. 차원축소(Dimensionality Reduction)

변수 선택에 의한 축소

원래 변수들 중 일부만 고르는 방식. (불필요한 변수 제거)

차원 축소(예: PCA, 요인분석)

원래 변수들을 선형결합하여 **새로운 변수(요인/주성분)**를 만들어 차원을 줄임.

차원: 변수의 수를 의미. 각 변수가 데이터 공간에서 하나의 축을 형성.

3. 요인분석 & PCA

요인분석(Factor Analysis)

독립변수/종속변수 구분 없음.

여러 변수들이 공유하는 **공통분산(공통된 변동성)**을 뽑아내어 숨겨진 요인을 찾음.

공통분산: 각 변수에 고유한 변동이 아니라, 여러 변수들이 같이 움직이는 정도를 의미.

PCA (주성분분석)

고차원(변수가 많아 축이 많은) 데이터를, 서로 선형연관성이 없는 저차원 축으로 변환.

목표: 분산(정보)을 최대한 유지하면서 축을 줄이는 것.

4. 행렬분해와 차원축소

SVD (특이값 분해)

행렬을 3개 행렬(좌직교행렬 × 대각행렬 × 우직교행렬)로 분해.

데이터 변환을 기하학적으로 "회전 → 크기 조정 → 회전"으로 해석 가능.

직교행렬: 열벡터들이 서로 직각(내적=0), 크기는 1 → 축이 서로 독립적.

대각행렬: 주대각선에만 값이 있음 → 각 축의 스케일만 바꿈.

5. 정규화(Normalization)

데이터 값을 0 ~ 1 사이로 변환

이상치(Outlier)에 민감 → $\max(x)$, $\min(x)$ 값이 이상치에 의해 크게 왜곡될 수 있음

Z-정규화 (표준화)

$\mu$: 평균 (Mean)

$\sigma$: 표준편차 (Standard Deviation)

변환 후 평균은 $0$, 표준편차는 $1$

분포의 모양(왜도, 척도)은 유지됨

평균 0, 표준편차 1로 변환.

하지만 데이터의 “모양(분포)”까지 같게 맞추는 건 아님 → 동일 척도라는 보장은 없음.

6. 분포와 왜도 (Skewness)

Skew(왜도): 데이터 분포가 한쪽으로 치우친 정도.

오른쪽 꼬리 길면 → 양(+)의 왜도.

변환 예시

오른쪽 치우침 보정 → $x^3$ 변환 등 사용.

7. 파생변수와 교호작용

파생변수: 기존 변수들로부터 새로운 의미 있는 변수를 생성.

특히 시간 종속적 데이터는 추세·주기 등 중요한 패턴을 담고 있어 파생변수로 활용 가치 높음.

교호작용(交互作用)

서로 교차(交), 번갈아(互) 영향을 미침.

즉, 두 변수의 결합 효과가 단순 합이 아니라 상호작용으로 결과에 영향을 줌.